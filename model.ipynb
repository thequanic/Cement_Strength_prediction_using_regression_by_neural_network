{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data=pd.read_csv(\"concrete_data.csv\")\n",
    "concrete_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1030, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>281.167864</td>\n",
       "      <td>73.895825</td>\n",
       "      <td>54.188350</td>\n",
       "      <td>181.567282</td>\n",
       "      <td>6.204660</td>\n",
       "      <td>972.918932</td>\n",
       "      <td>773.580485</td>\n",
       "      <td>45.662136</td>\n",
       "      <td>35.817961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.506364</td>\n",
       "      <td>86.279342</td>\n",
       "      <td>63.997004</td>\n",
       "      <td>21.354219</td>\n",
       "      <td>5.973841</td>\n",
       "      <td>77.753954</td>\n",
       "      <td>80.175980</td>\n",
       "      <td>63.169912</td>\n",
       "      <td>16.705742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>192.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>730.950000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>272.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>779.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>118.300000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>1029.400000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>46.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>540.000000</td>\n",
       "      <td>359.400000</td>\n",
       "      <td>200.100000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>992.600000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>82.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Cement  Blast Furnace Slag      Fly Ash        Water  \\\n",
       "count  1030.000000         1030.000000  1030.000000  1030.000000   \n",
       "mean    281.167864           73.895825    54.188350   181.567282   \n",
       "std     104.506364           86.279342    63.997004    21.354219   \n",
       "min     102.000000            0.000000     0.000000   121.800000   \n",
       "25%     192.375000            0.000000     0.000000   164.900000   \n",
       "50%     272.900000           22.000000     0.000000   185.000000   \n",
       "75%     350.000000          142.950000   118.300000   192.000000   \n",
       "max     540.000000          359.400000   200.100000   247.000000   \n",
       "\n",
       "       Superplasticizer  Coarse Aggregate  Fine Aggregate          Age  \\\n",
       "count       1030.000000       1030.000000     1030.000000  1030.000000   \n",
       "mean           6.204660        972.918932      773.580485    45.662136   \n",
       "std            5.973841         77.753954       80.175980    63.169912   \n",
       "min            0.000000        801.000000      594.000000     1.000000   \n",
       "25%            0.000000        932.000000      730.950000     7.000000   \n",
       "50%            6.400000        968.000000      779.500000    28.000000   \n",
       "75%           10.200000       1029.400000      824.000000    56.000000   \n",
       "max           32.200000       1145.000000      992.600000   365.000000   \n",
       "\n",
       "          Strength  \n",
       "count  1030.000000  \n",
       "mean     35.817961  \n",
       "std      16.705742  \n",
       "min       2.330000  \n",
       "25%      23.710000  \n",
       "50%      34.445000  \n",
       "75%      46.135000  \n",
       "max      82.600000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FINDING IF ANY NULL VALUE IN DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cement                0\n",
       "Blast Furnace Slag    0\n",
       "Fly Ash               0\n",
       "Water                 0\n",
       "Superplasticizer      0\n",
       "Coarse Aggregate      0\n",
       "Fine Aggregate        0\n",
       "Age                   0\n",
       "Strength              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBTAINING INPUTS AND OUTPUT FROM DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Cement', 'Blast Furnace Slag', 'Fly Ash', 'Water', 'Superplasticizer',\n",
       "       'Coarse Aggregate', 'Fine Aggregate', 'Age', 'Strength'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data_col=concrete_data.columns\n",
    "concrete_data_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  \n",
       "0            1040.0           676.0   28  \n",
       "1            1055.0           676.0   28  \n",
       "2             932.0           594.0  270  \n",
       "3             932.0           594.0  365  \n",
       "4             978.4           825.5  360  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors=concrete_data[concrete_data_col[concrete_data_col!=\"Strength\"]]\n",
    "predictors.shape\n",
    "predictors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    79.99\n",
       "1    61.89\n",
       "2    40.27\n",
       "3    41.05\n",
       "4    44.30\n",
       "Name: Strength, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target=concrete_data[\"Strength\"]\n",
    "target.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FINDING NORMALIZED INPUTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>0.862735</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>1.055651</td>\n",
       "      <td>-1.217079</td>\n",
       "      <td>-0.279597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>3.551340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "      <td>5.055221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.790075</td>\n",
       "      <td>0.678079</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>0.488555</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>0.070492</td>\n",
       "      <td>0.647569</td>\n",
       "      <td>4.976069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
       "0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "3  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "4 -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate       Age  \n",
       "0          0.862735       -1.217079 -0.279597  \n",
       "1          1.055651       -1.217079 -0.279597  \n",
       "2         -0.526262       -2.239829  3.551340  \n",
       "3         -0.526262       -2.239829  5.055221  \n",
       "4          0.070492        0.647569  4.976069  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors_norm=(predictors-predictors.mean())/predictors.std()\n",
    "predictors_norm.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***FINDING NUMBER OF COLUMNS IN PREDICTORS(INPUT)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "n_col=predictors.shape[1]\n",
    "print(n_col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART A: NEURAL NETWORK WITH 1 HIDDEN LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyModel1():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(10,activation=\"relu\",input_shape=(n_col,)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=\"adam\",loss=\"mean_squared_error\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**USING PREDICTORS AS INPUT AND TRAING AND CALCULATING ERROR FROM NEURAL NETWORK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyModel1_eval():\n",
    "    x_train,x_test,y_train,y_test=train_test_split(predictors,target,test_size=0.3)\n",
    "    model=MyModel1()\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=50)\n",
    "    y_pred_test=model.predict(x_test)\n",
    "    error=mean_squared_error(y_test,y_pred_test)\n",
    "    return error\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CALCULATING MEAN SQUARED ERROR FOR NEURAL NETWORK 50 TIMES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 15705.8281 - val_loss: 4663.8838\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1563.0490 - val_loss: 449.9941\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 484.7023 - val_loss: 443.6889\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 399.8060 - val_loss: 387.0565\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 366.4819 - val_loss: 356.9776\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 338.2344 - val_loss: 327.3444\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 312.4974 - val_loss: 300.8849\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 288.0865 - val_loss: 276.6740\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 266.6523 - val_loss: 254.8058\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 246.8011 - val_loss: 235.2644\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 228.7774 - val_loss: 217.5041\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 212.3113 - val_loss: 201.9448\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.8774 - val_loss: 188.5846\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 185.4150 - val_loss: 177.5735\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 174.4229 - val_loss: 168.0795\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 165.0109 - val_loss: 159.2934\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 156.7889 - val_loss: 152.2240\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 149.5325 - val_loss: 146.5368\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 143.7735 - val_loss: 141.2017\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.3730 - val_loss: 137.8552\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.1655 - val_loss: 133.4951\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.5506 - val_loss: 130.5562\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.4478 - val_loss: 127.9359\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.6511 - val_loss: 126.7829\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.1796 - val_loss: 124.1154\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 120.5265 - val_loss: 123.4425\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 118.4794 - val_loss: 121.9428\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 117.1831 - val_loss: 120.8646\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 115.7994 - val_loss: 120.9835\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 114.8531 - val_loss: 120.5067\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 114.1192 - val_loss: 118.7947\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 114.8043 - val_loss: 121.1684\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 113.9190 - val_loss: 120.9714\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 113.0507 - val_loss: 117.7254\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 113.6448 - val_loss: 117.5065\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 112.3662 - val_loss: 117.1471\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 113.6544 - val_loss: 122.9396\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 111.1039 - val_loss: 116.9030\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 111.2003 - val_loss: 119.1142\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 111.3744 - val_loss: 121.1317\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 111.4042 - val_loss: 116.1868\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 109.6670 - val_loss: 118.3460\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 109.6896 - val_loss: 116.1460\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 109.5745 - val_loss: 116.3147\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 109.1202 - val_loss: 120.3017\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 109.0231 - val_loss: 118.0751\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 109.9792 - val_loss: 116.7030\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 109.6562 - val_loss: 121.2227\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 108.7251 - val_loss: 115.5695\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 109.2162 - val_loss: 116.1331\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 340936.1562 - val_loss: 232502.2344\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 167978.3594 - val_loss: 108616.3359\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 76109.4844 - val_loss: 46270.1055\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 31804.2637 - val_loss: 18786.4297\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 13023.9824 - val_loss: 7924.1738\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 6036.2061 - val_loss: 4214.3726\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3745.0620 - val_loss: 3167.4062\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3109.8699 - val_loss: 2864.6663\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2907.5220 - val_loss: 2751.3567\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2807.0554 - val_loss: 2660.5039\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2723.0442 - val_loss: 2577.9841\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2632.3586 - val_loss: 2496.7302\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2550.6873 - val_loss: 2415.0479\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2468.1384 - val_loss: 2334.0676\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2384.8047 - val_loss: 2254.6699\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2307.3074 - val_loss: 2176.3462\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2232.9211 - val_loss: 2100.8281\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2156.2993 - val_loss: 2030.0247\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2084.6648 - val_loss: 1961.6998\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2015.3911 - val_loss: 1899.3115\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1951.3370 - val_loss: 1834.8876\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1887.7847 - val_loss: 1776.5751\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1829.1556 - val_loss: 1717.8369\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1771.9901 - val_loss: 1665.3435\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1718.4943 - val_loss: 1612.5988\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1667.5717 - val_loss: 1565.7960\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1617.1510 - val_loss: 1519.3062\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1571.7888 - val_loss: 1476.5255\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1528.8615 - val_loss: 1437.1448\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1486.3219 - val_loss: 1395.5142\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1447.4742 - val_loss: 1360.6509\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1411.2668 - val_loss: 1327.9926\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1376.1061 - val_loss: 1294.0532\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1342.6741 - val_loss: 1265.7274\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1312.4980 - val_loss: 1236.6648\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1283.1475 - val_loss: 1210.8516\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1252.8629 - val_loss: 1183.8093\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1227.1042 - val_loss: 1157.9786\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1201.6700 - val_loss: 1134.4896\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1175.7192 - val_loss: 1111.8302\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1154.0040 - val_loss: 1089.7261\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1131.8364 - val_loss: 1067.3508\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1106.8788 - val_loss: 1047.3451\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1084.9265 - val_loss: 1027.8503\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1064.0895 - val_loss: 1007.1496\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1043.6339 - val_loss: 988.1273\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1023.9540 - val_loss: 969.7248\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1005.4985 - val_loss: 951.7516\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 987.2209 - val_loss: 933.9086\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 969.4942 - val_loss: 917.8675\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 4831.5728 - val_loss: 1147.9413\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 765.7593 - val_loss: 823.5411\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 682.8735 - val_loss: 721.9155\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 610.6892 - val_loss: 666.6550\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 571.9843 - val_loss: 613.2352\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 535.5148 - val_loss: 571.4521\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 505.3125 - val_loss: 531.1331\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 474.8729 - val_loss: 502.8468\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 451.4297 - val_loss: 467.9431\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 430.4680 - val_loss: 443.1376\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 408.4278 - val_loss: 419.9667\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 392.6650 - val_loss: 402.4844\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 372.3087 - val_loss: 381.0757\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 357.3410 - val_loss: 366.1121\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 343.7499 - val_loss: 353.1628\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 331.8848 - val_loss: 344.1599\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 319.9474 - val_loss: 326.7018\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.1802 - val_loss: 319.9675\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 296.1357 - val_loss: 305.9611\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 286.9454 - val_loss: 297.9621\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 278.4458 - val_loss: 293.8869\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 267.7984 - val_loss: 279.7112\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 260.3715 - val_loss: 273.5884\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 252.5602 - val_loss: 266.4367\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 246.4253 - val_loss: 257.4544\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 242.1136 - val_loss: 256.7652\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 233.6292 - val_loss: 246.0042\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 230.1385 - val_loss: 240.3636\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 224.1962 - val_loss: 236.7847\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 218.1496 - val_loss: 234.0248\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 214.6964 - val_loss: 232.4617\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 211.6651 - val_loss: 229.5286\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 207.2425 - val_loss: 219.0416\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 207.0062 - val_loss: 215.2483\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 200.4680 - val_loss: 211.9038\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 197.6969 - val_loss: 217.1088\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 193.8066 - val_loss: 210.2542\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 190.1918 - val_loss: 202.1909\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 186.3656 - val_loss: 202.1639\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 186.2140 - val_loss: 194.7661\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 180.1865 - val_loss: 196.8828\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 179.1529 - val_loss: 192.6403\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 177.3669 - val_loss: 192.0714\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 174.0807 - val_loss: 184.1204\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 171.4389 - val_loss: 184.1553\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 170.0332 - val_loss: 180.0754\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 169.1606 - val_loss: 180.2711\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 167.0589 - val_loss: 174.3975\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.6860 - val_loss: 170.7137\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.0434 - val_loss: 176.6030\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 63120.0156 - val_loss: 31921.8027\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 18658.6191 - val_loss: 8739.0918\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 6188.7456 - val_loss: 3959.9971\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4079.7417 - val_loss: 3492.8071\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3811.4622 - val_loss: 3315.9109\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3600.6338 - val_loss: 3138.5044\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3397.7524 - val_loss: 2955.2336\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3180.6453 - val_loss: 2781.5288\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2976.2288 - val_loss: 2610.0513\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2781.3228 - val_loss: 2441.9905\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2594.0876 - val_loss: 2282.0098\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2397.7605 - val_loss: 2122.4097\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2211.7627 - val_loss: 1960.5898\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2016.5073 - val_loss: 1816.4929\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1861.4625 - val_loss: 1695.2406\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1732.9360 - val_loss: 1592.3905\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1616.8651 - val_loss: 1491.8484\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1504.5874 - val_loss: 1405.2452\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1410.1556 - val_loss: 1314.0737\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1311.2089 - val_loss: 1233.4186\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1222.8007 - val_loss: 1160.0052\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1143.2428 - val_loss: 1085.4779\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1064.5319 - val_loss: 1019.2407\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 994.8756 - val_loss: 959.0111\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 931.9974 - val_loss: 900.6661\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 871.4860 - val_loss: 849.2223\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 817.4022 - val_loss: 799.1676\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 767.5305 - val_loss: 752.6786\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 721.5359 - val_loss: 709.3610\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 677.1526 - val_loss: 672.4857\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 634.9816 - val_loss: 633.9758\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 601.0212 - val_loss: 599.4436\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 568.1632 - val_loss: 566.9007\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 537.6328 - val_loss: 537.8644\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 505.7856 - val_loss: 510.6598\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 480.9085 - val_loss: 485.7596\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 456.2079 - val_loss: 463.1994\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 433.9988 - val_loss: 439.9808\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 412.4046 - val_loss: 419.9221\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 393.3956 - val_loss: 401.2565\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 374.8757 - val_loss: 383.7965\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 358.9133 - val_loss: 368.0439\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 344.5375 - val_loss: 353.5403\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 332.0098 - val_loss: 340.7838\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 319.0584 - val_loss: 327.6855\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 307.3844 - val_loss: 316.8545\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 297.6275 - val_loss: 305.9788\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 287.5284 - val_loss: 296.6407\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 279.6273 - val_loss: 287.6089\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 271.2974 - val_loss: 279.4791\n",
      "10/10 [==============================] - 0s 785us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 4126.8447 - val_loss: 3223.3643\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2152.1055 - val_loss: 1696.9520\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1173.1427 - val_loss: 1025.9664\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 699.1468 - val_loss: 656.7703\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 457.9484 - val_loss: 461.5562\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 346.4612 - val_loss: 364.0711\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 291.1462 - val_loss: 325.0050\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 260.1799 - val_loss: 280.2111\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 238.4402 - val_loss: 259.6615\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 222.8276 - val_loss: 239.2690\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 209.1281 - val_loss: 224.5910\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 200.2712 - val_loss: 209.3537\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 189.5225 - val_loss: 200.5536\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 182.4533 - val_loss: 189.8043\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 175.5743 - val_loss: 181.7290\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 169.1272 - val_loss: 175.4563\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 163.4874 - val_loss: 168.7423\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.6122 - val_loss: 164.2595\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 154.0392 - val_loss: 159.6146\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.7803 - val_loss: 156.5952\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.9519 - val_loss: 149.9426\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.6909 - val_loss: 147.2958\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.0330 - val_loss: 142.5971\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.7533 - val_loss: 143.4460\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 134.6545 - val_loss: 143.2806\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 134.9715 - val_loss: 135.1677\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 131.9570 - val_loss: 133.6427\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.8078 - val_loss: 131.0791\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 129.1563 - val_loss: 143.6557\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.1161 - val_loss: 140.2554\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 126.1668 - val_loss: 127.1275\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.1392 - val_loss: 127.4995\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 123.6773 - val_loss: 126.4455\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 124.9171 - val_loss: 123.6595\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 121.3744 - val_loss: 123.5911\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 119.3683 - val_loss: 129.9258\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 119.9578 - val_loss: 121.6531\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 118.1957 - val_loss: 120.2609\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 116.7548 - val_loss: 122.9825\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 116.0648 - val_loss: 121.0616\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 116.6572 - val_loss: 118.9616\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 115.4329 - val_loss: 119.5465\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 115.3309 - val_loss: 117.6651\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 115.1440 - val_loss: 117.4441\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.4131 - val_loss: 117.4711\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.6873 - val_loss: 118.6683\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 117.8570 - val_loss: 123.1389\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 114.7057 - val_loss: 119.9304\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 113.5517 - val_loss: 115.8531\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 113.3417 - val_loss: 116.1705\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 3206.9646 - val_loss: 2042.6924\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1506.9863 - val_loss: 1295.0734\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 855.7070 - val_loss: 643.1401\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 432.6262 - val_loss: 378.4755\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 308.6749 - val_loss: 317.1745\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 266.4857 - val_loss: 283.1774\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 245.6377 - val_loss: 262.6233\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 224.9231 - val_loss: 245.0086\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 211.6731 - val_loss: 231.5718\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 199.2612 - val_loss: 221.1923\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 193.9944 - val_loss: 212.3837\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.7274 - val_loss: 203.6919\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 174.1409 - val_loss: 196.9798\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 167.3049 - val_loss: 191.1870\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 161.7385 - val_loss: 185.3796\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 156.7331 - val_loss: 183.8186\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 151.4419 - val_loss: 175.5166\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.6039 - val_loss: 175.6447\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.1123 - val_loss: 168.7774\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 138.2563 - val_loss: 162.7803\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 134.2227 - val_loss: 158.4331\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 129.7329 - val_loss: 155.6801\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 127.4094 - val_loss: 154.6542\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 123.1601 - val_loss: 149.0151\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 120.2978 - val_loss: 146.2682\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 119.1425 - val_loss: 142.6311\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 116.9067 - val_loss: 141.9278\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 112.8807 - val_loss: 142.1490\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 115.2575 - val_loss: 137.6847\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 112.6471 - val_loss: 136.1816\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 111.5077 - val_loss: 139.6022\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 110.0270 - val_loss: 134.1316\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 107.8459 - val_loss: 133.9634\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 108.2975 - val_loss: 133.2527\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 109.9296 - val_loss: 133.3548\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 106.8969 - val_loss: 131.8315\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 107.6248 - val_loss: 136.5992\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 108.0951 - val_loss: 137.4121\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 107.1154 - val_loss: 130.8047\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 107.2671 - val_loss: 131.6563\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 106.1727 - val_loss: 131.3631\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 105.9051 - val_loss: 130.6886\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 107.0778 - val_loss: 147.0433\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 116.6607 - val_loss: 129.4458\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 107.1611 - val_loss: 130.7544\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 105.3497 - val_loss: 129.2971\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 106.5187 - val_loss: 131.5632\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 106.7886 - val_loss: 132.8231\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 103.7423 - val_loss: 129.0740\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 103.9691 - val_loss: 130.2776\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 559039.3125 - val_loss: 431606.5000\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 335804.9688 - val_loss: 254531.6719\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 190524.9219 - val_loss: 134950.6719\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 84742.9453 - val_loss: 46896.1992\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24688.5957 - val_loss: 12112.6172\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 7302.6802 - val_loss: 5238.2046\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 4975.9966 - val_loss: 4465.2759\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4677.1030 - val_loss: 4223.7197\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4432.5957 - val_loss: 4012.2847\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4200.4829 - val_loss: 3813.7883\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3971.7986 - val_loss: 3577.2979\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3755.6592 - val_loss: 3366.7573\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3551.5974 - val_loss: 3185.9458\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3353.2615 - val_loss: 2997.6101\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3170.0728 - val_loss: 2836.5171\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2998.0461 - val_loss: 2656.1890\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2831.8269 - val_loss: 2520.5396\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2678.9607 - val_loss: 2369.5500\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2531.8950 - val_loss: 2231.2891\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2397.0901 - val_loss: 2108.5598\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2270.9717 - val_loss: 2002.0184\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2156.5940 - val_loss: 1885.8289\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2043.0112 - val_loss: 1799.5579\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1940.5750 - val_loss: 1701.4917\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1842.8223 - val_loss: 1616.8989\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1756.1910 - val_loss: 1537.7325\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1671.8866 - val_loss: 1456.0784\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1601.6536 - val_loss: 1389.0492\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1525.3173 - val_loss: 1329.9080\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1459.9095 - val_loss: 1274.6854\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1399.3051 - val_loss: 1221.2904\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1342.4633 - val_loss: 1174.9584\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1288.5956 - val_loss: 1131.7454\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1239.8096 - val_loss: 1085.5704\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1195.0164 - val_loss: 1052.6084\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1150.8990 - val_loss: 1010.5611\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1113.8978 - val_loss: 978.6063\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1076.1322 - val_loss: 946.1426\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1039.5944 - val_loss: 915.5049\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1006.8511 - val_loss: 885.2048\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 978.9684 - val_loss: 865.6327\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 947.6765 - val_loss: 833.2537\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 923.4227 - val_loss: 818.4706\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 896.1183 - val_loss: 787.9142\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 872.3856 - val_loss: 774.1009\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 850.5332 - val_loss: 757.7274\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 832.9102 - val_loss: 738.6155\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 808.8030 - val_loss: 723.8456\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 789.2399 - val_loss: 703.4850\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 770.3730 - val_loss: 685.2227\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 2709.2954 - val_loss: 2265.3376\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1758.7325 - val_loss: 1565.6025\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1253.2988 - val_loss: 1198.0709\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 973.1776 - val_loss: 913.9305\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 759.5397 - val_loss: 770.8218\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 608.6309 - val_loss: 613.1717\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 487.6313 - val_loss: 486.9334\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 392.9529 - val_loss: 391.3310\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 316.5196 - val_loss: 335.9083\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 275.2787 - val_loss: 275.4564\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 221.1945 - val_loss: 218.1148\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 193.0627 - val_loss: 194.0078\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 167.4266 - val_loss: 167.1424\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.7834 - val_loss: 151.6554\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.7565 - val_loss: 142.6885\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 125.0633 - val_loss: 126.3393\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 116.5450 - val_loss: 120.1320\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 113.5606 - val_loss: 122.6388\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 110.5536 - val_loss: 108.4086\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 105.9782 - val_loss: 98.1142\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 102.1055 - val_loss: 95.1035\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 100.2400 - val_loss: 97.5513\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 100.0782 - val_loss: 92.9226\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 97.6635 - val_loss: 104.8426\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 101.0986 - val_loss: 89.6153\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 96.9450 - val_loss: 93.1499\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 97.5018 - val_loss: 89.4418\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 97.3028 - val_loss: 87.0716\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 99.5649 - val_loss: 93.2889\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 96.3141 - val_loss: 87.5093\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 95.8598 - val_loss: 86.8262\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 96.9434 - val_loss: 86.2601\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 94.9562 - val_loss: 85.7793\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 93.9500 - val_loss: 88.0077\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 95.5251 - val_loss: 85.6144\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 93.7466 - val_loss: 84.9688\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 92.9746 - val_loss: 84.7994\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 93.0361 - val_loss: 83.7054\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 92.5648 - val_loss: 83.6571\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 91.5275 - val_loss: 82.6603\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 92.9683 - val_loss: 81.8153\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 90.8920 - val_loss: 86.3310\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 90.4669 - val_loss: 84.7859\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 89.9772 - val_loss: 86.0031\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 91.5163 - val_loss: 79.2754\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 88.9805 - val_loss: 79.2658\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 89.2935 - val_loss: 79.5828\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 88.0745 - val_loss: 81.1882\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 87.9194 - val_loss: 77.1107\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 87.3040 - val_loss: 78.7553\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 6673.5664 - val_loss: 3707.3799\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2502.9453 - val_loss: 1673.3850\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1352.2567 - val_loss: 1186.5929\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1069.8682 - val_loss: 1049.4680\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 973.1388 - val_loss: 983.5479\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 915.2419 - val_loss: 923.2942\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 860.9308 - val_loss: 861.6772\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 805.6387 - val_loss: 793.7039\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 744.4880 - val_loss: 723.0609\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 679.0666 - val_loss: 650.5604\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 615.4636 - val_loss: 581.3563\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 556.0765 - val_loss: 519.4975\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 508.4258 - val_loss: 473.5965\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 474.9659 - val_loss: 445.3676\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 452.9631 - val_loss: 425.6534\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 437.6935 - val_loss: 411.0407\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 425.7980 - val_loss: 399.1696\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 415.6157 - val_loss: 389.8005\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 406.9833 - val_loss: 381.4225\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 399.0124 - val_loss: 373.6790\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 391.9047 - val_loss: 366.8267\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 386.1531 - val_loss: 360.9620\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 380.3256 - val_loss: 355.6356\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 375.3329 - val_loss: 350.9072\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 370.9514 - val_loss: 345.9758\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 366.4085 - val_loss: 341.6654\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 362.4454 - val_loss: 337.2985\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 358.5923 - val_loss: 333.4970\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 354.6972 - val_loss: 329.6114\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 350.9671 - val_loss: 325.9128\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 347.5233 - val_loss: 322.5605\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 344.3719 - val_loss: 319.2249\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 341.5560 - val_loss: 316.1039\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 338.5645 - val_loss: 313.4089\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 335.2823 - val_loss: 310.1294\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 332.7389 - val_loss: 307.2444\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 330.3338 - val_loss: 304.6945\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 327.3427 - val_loss: 301.9476\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 325.5854 - val_loss: 299.3565\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 322.5751 - val_loss: 297.2131\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 320.3115 - val_loss: 294.5991\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 318.2930 - val_loss: 292.2491\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 316.1072 - val_loss: 290.4840\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 313.9345 - val_loss: 287.6564\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 311.7043 - val_loss: 285.8953\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 309.5489 - val_loss: 283.5553\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 307.5657 - val_loss: 281.5430\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 305.3981 - val_loss: 279.4850\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 304.2795 - val_loss: 277.7412\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 301.6506 - val_loss: 275.6570\n",
      "10/10 [==============================] - 0s 908us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 17ms/step - loss: 15151.6367 - val_loss: 10392.9414\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 8102.8174 - val_loss: 4714.4170\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3414.0088 - val_loss: 1816.8938\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1513.9469 - val_loss: 1283.5767\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1173.7433 - val_loss: 1131.9722\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1029.6804 - val_loss: 990.7003\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 910.9984 - val_loss: 887.2996\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 814.4316 - val_loss: 801.2484\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 734.4645 - val_loss: 726.9625\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 665.7944 - val_loss: 659.1399\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 607.5765 - val_loss: 605.6183\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 558.1495 - val_loss: 557.2635\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 514.5518 - val_loss: 519.2487\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 477.3595 - val_loss: 482.9018\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 445.3459 - val_loss: 449.9289\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 417.3892 - val_loss: 426.7208\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 392.5394 - val_loss: 401.8539\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 369.6602 - val_loss: 381.3939\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 350.6898 - val_loss: 362.3826\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 332.8582 - val_loss: 344.0387\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 318.4210 - val_loss: 331.1257\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 303.8946 - val_loss: 316.4753\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 291.5878 - val_loss: 305.8332\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 280.5529 - val_loss: 295.9377\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 270.7190 - val_loss: 284.4162\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 261.3442 - val_loss: 276.1667\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 253.2101 - val_loss: 268.8805\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 245.5420 - val_loss: 260.1168\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 238.0662 - val_loss: 255.3689\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 231.8350 - val_loss: 249.3739\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 226.1971 - val_loss: 242.2781\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 220.0213 - val_loss: 238.0665\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 215.1039 - val_loss: 232.2533\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 210.6214 - val_loss: 228.8991\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 206.2923 - val_loss: 222.8051\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 201.6487 - val_loss: 220.6924\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.7525 - val_loss: 215.7853\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.3084 - val_loss: 213.7747\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 191.3332 - val_loss: 209.8687\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 188.1320 - val_loss: 206.2377\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 185.4547 - val_loss: 205.6649\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 183.2103 - val_loss: 201.1684\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 180.4105 - val_loss: 200.8741\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 178.1277 - val_loss: 196.9773\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 176.2144 - val_loss: 195.2669\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.1221 - val_loss: 193.7183\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.3018 - val_loss: 191.2138\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 171.2094 - val_loss: 190.2848\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.7881 - val_loss: 187.9800\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 167.4684 - val_loss: 187.6270\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 17962.3516 - val_loss: 6448.4619\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3843.7095 - val_loss: 3668.3484\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3106.9463 - val_loss: 3224.4438\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2767.4399 - val_loss: 2924.8259\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2476.9082 - val_loss: 2640.4905\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2229.0500 - val_loss: 2394.5195\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2005.7074 - val_loss: 2169.5808\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1798.1914 - val_loss: 1966.0582\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1614.5492 - val_loss: 1773.2913\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1446.2271 - val_loss: 1609.2981\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1297.0098 - val_loss: 1437.8071\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1166.0833 - val_loss: 1314.2234\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1037.0264 - val_loss: 1179.1599\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 928.7751 - val_loss: 1056.4569\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 833.1388 - val_loss: 957.1190\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 747.4058 - val_loss: 866.3367\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 674.6417 - val_loss: 780.0997\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 608.5867 - val_loss: 710.1212\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 550.5408 - val_loss: 632.1545\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 494.5976 - val_loss: 566.3618\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 444.2213 - val_loss: 520.7342\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 402.3947 - val_loss: 473.1974\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 366.8300 - val_loss: 429.2471\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 339.8398 - val_loss: 403.7230\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 315.0568 - val_loss: 379.9074\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 296.6711 - val_loss: 350.3475\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 279.5036 - val_loss: 327.4817\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 265.4636 - val_loss: 327.0330\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 254.9527 - val_loss: 293.7540\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 246.1074 - val_loss: 293.5810\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 237.2938 - val_loss: 283.9052\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 227.5795 - val_loss: 271.0540\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 220.5468 - val_loss: 272.3044\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 218.1431 - val_loss: 251.9082\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 209.7661 - val_loss: 248.7732\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 204.7956 - val_loss: 243.4835\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 200.4733 - val_loss: 232.8081\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.3722 - val_loss: 231.2407\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 194.1800 - val_loss: 241.5247\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 192.2280 - val_loss: 229.9969\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.7049 - val_loss: 217.0819\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 184.2453 - val_loss: 208.8766\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.5279 - val_loss: 214.2695\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 178.2435 - val_loss: 204.8430\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 175.8471 - val_loss: 204.5327\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 173.2304 - val_loss: 205.7106\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.2595 - val_loss: 196.7602\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.2391 - val_loss: 205.9593\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.0301 - val_loss: 189.4256\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.6989 - val_loss: 195.0016\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 45283.3867 - val_loss: 27033.2285\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 18078.2227 - val_loss: 9369.8047\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 6131.5000 - val_loss: 3404.1587\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2712.5659 - val_loss: 2287.7771\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2163.7085 - val_loss: 2169.3650\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2055.3818 - val_loss: 2068.3779\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1913.5491 - val_loss: 1895.2839\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1658.6515 - val_loss: 1552.6737\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1360.3859 - val_loss: 1300.0751\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1120.4841 - val_loss: 1088.2858\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 941.4400 - val_loss: 925.7754\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 791.2554 - val_loss: 760.5960\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 667.6667 - val_loss: 644.4185\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 570.6958 - val_loss: 544.2954\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 496.3263 - val_loss: 475.7047\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 436.6456 - val_loss: 417.4590\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 388.7958 - val_loss: 363.5362\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 349.2625 - val_loss: 325.0199\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 315.5992 - val_loss: 286.1888\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 288.0814 - val_loss: 266.3600\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 265.0846 - val_loss: 247.7734\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 245.3042 - val_loss: 218.1713\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 231.7659 - val_loss: 205.5632\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 217.1057 - val_loss: 200.4363\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 207.4909 - val_loss: 189.1325\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 198.9925 - val_loss: 183.1202\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 190.9022 - val_loss: 174.9969\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 184.6954 - val_loss: 173.0544\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.5851 - val_loss: 169.9494\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.9571 - val_loss: 164.0348\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.1085 - val_loss: 168.6985\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.0232 - val_loss: 155.9429\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159.1917 - val_loss: 155.8110\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.4586 - val_loss: 150.7332\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.7006 - val_loss: 154.7109\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 148.2173 - val_loss: 149.2277\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 145.9459 - val_loss: 148.1877\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 144.7469 - val_loss: 148.2418\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.0759 - val_loss: 152.7305\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.6377 - val_loss: 143.1118\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 135.3220 - val_loss: 139.5497\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.0049 - val_loss: 138.0946\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.5463 - val_loss: 137.4592\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 131.4399 - val_loss: 135.1864\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.3745 - val_loss: 134.1762\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 126.2725 - val_loss: 136.8991\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.8613 - val_loss: 131.6549\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 124.6897 - val_loss: 130.9136\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.6931 - val_loss: 130.0682\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 120.8385 - val_loss: 134.4810\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 24651.4766 - val_loss: 9177.0752\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4525.1021 - val_loss: 3249.1799\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2672.5117 - val_loss: 2999.6470\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2468.5366 - val_loss: 2748.6868\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2252.2280 - val_loss: 2535.9084\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2054.2766 - val_loss: 2303.8289\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1862.4978 - val_loss: 2101.6226\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1692.2932 - val_loss: 1906.5095\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1521.9688 - val_loss: 1728.7013\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1369.2201 - val_loss: 1552.7457\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1231.3530 - val_loss: 1397.9698\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1102.5192 - val_loss: 1260.9171\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 987.7897 - val_loss: 1133.7933\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 887.5018 - val_loss: 1011.3481\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 795.0572 - val_loss: 905.3583\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 711.7184 - val_loss: 811.3990\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 637.5956 - val_loss: 727.8073\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 570.7380 - val_loss: 648.3692\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 513.5415 - val_loss: 583.6335\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 463.7812 - val_loss: 525.1188\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 416.9101 - val_loss: 470.0169\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 377.0414 - val_loss: 425.2513\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 343.6433 - val_loss: 384.3406\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 314.1496 - val_loss: 353.6056\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 290.3905 - val_loss: 322.7787\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 271.6894 - val_loss: 300.5135\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 252.8351 - val_loss: 281.5309\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 239.4716 - val_loss: 264.9442\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 226.6985 - val_loss: 248.4312\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 215.4839 - val_loss: 237.9543\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 207.1835 - val_loss: 226.5772\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 199.7304 - val_loss: 217.3460\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.4280 - val_loss: 211.7161\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 187.7822 - val_loss: 203.8618\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 182.6888 - val_loss: 197.2781\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.7725 - val_loss: 194.0836\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.7730 - val_loss: 188.4960\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.0650 - val_loss: 181.8805\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.2770 - val_loss: 180.1648\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 163.8869 - val_loss: 173.8540\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 160.5162 - val_loss: 172.4557\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.0824 - val_loss: 168.9015\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 155.3932 - val_loss: 167.7934\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152.3323 - val_loss: 162.0876\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 150.4427 - val_loss: 161.3240\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.7877 - val_loss: 157.3208\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 146.3723 - val_loss: 154.8981\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.8362 - val_loss: 154.5141\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 141.6072 - val_loss: 151.1653\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.4565 - val_loss: 149.9844\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 286744.6875 - val_loss: 202550.5938\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 145527.3750 - val_loss: 98864.1406\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 68550.1406 - val_loss: 43509.9375\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27696.5137 - val_loss: 15119.6377\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 8230.7783 - val_loss: 3866.4446\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2324.5613 - val_loss: 1812.0314\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1602.3486 - val_loss: 1647.5740\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1506.2041 - val_loss: 1577.0920\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1435.4669 - val_loss: 1514.2533\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1371.1660 - val_loss: 1445.3304\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1305.9401 - val_loss: 1376.9742\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1244.8206 - val_loss: 1315.4099\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1187.0883 - val_loss: 1256.4076\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1132.0988 - val_loss: 1202.1490\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1080.2744 - val_loss: 1151.7643\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1029.5986 - val_loss: 1102.8318\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 985.8692 - val_loss: 1061.9673\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 944.3882 - val_loss: 1019.3761\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 906.5823 - val_loss: 981.7595\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 872.4442 - val_loss: 949.2620\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 842.2442 - val_loss: 916.3820\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 813.7948 - val_loss: 886.6924\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 786.8746 - val_loss: 860.6113\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 761.9058 - val_loss: 833.9496\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 736.0647 - val_loss: 814.6830\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 714.2940 - val_loss: 790.7832\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 693.0599 - val_loss: 765.9893\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 673.1179 - val_loss: 749.7688\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 655.7484 - val_loss: 727.8246\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 638.3921 - val_loss: 711.3636\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 620.4631 - val_loss: 693.8173\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 604.2318 - val_loss: 676.5306\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 588.3748 - val_loss: 666.4738\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 573.0305 - val_loss: 644.4904\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 558.4313 - val_loss: 627.9404\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 544.5231 - val_loss: 613.8970\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 530.3696 - val_loss: 596.1771\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 516.4598 - val_loss: 581.9075\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 502.7170 - val_loss: 566.1396\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 490.7898 - val_loss: 550.2828\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 478.4277 - val_loss: 539.1334\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 466.4711 - val_loss: 524.2863\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 454.9637 - val_loss: 513.3342\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 443.8111 - val_loss: 501.1624\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 433.8335 - val_loss: 488.1649\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 422.6981 - val_loss: 475.2400\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 412.8158 - val_loss: 464.1362\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 402.6960 - val_loss: 451.7715\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 393.0907 - val_loss: 441.5877\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 383.6199 - val_loss: 430.0870\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 254582.1094 - val_loss: 190356.6094\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139307.4844 - val_loss: 94422.8438\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 63324.3789 - val_loss: 38568.6680\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 23226.8906 - val_loss: 12524.3047\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 6754.7471 - val_loss: 3583.4224\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2008.8652 - val_loss: 1464.5698\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1137.5682 - val_loss: 1107.5674\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1038.7899 - val_loss: 1041.2679\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1002.0631 - val_loss: 1001.3253\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 967.0778 - val_loss: 965.9838\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 931.4022 - val_loss: 926.4766\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 895.5515 - val_loss: 889.0437\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 859.8088 - val_loss: 851.9648\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 824.7480 - val_loss: 819.4848\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 790.7409 - val_loss: 781.3799\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 756.7457 - val_loss: 742.7968\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 723.5373 - val_loss: 711.1698\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 690.7487 - val_loss: 679.9852\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 662.1237 - val_loss: 642.6642\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 630.5010 - val_loss: 615.2228\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 601.5208 - val_loss: 584.6710\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 573.4620 - val_loss: 553.2300\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 547.1901 - val_loss: 531.5068\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 521.4878 - val_loss: 501.0875\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 495.9631 - val_loss: 473.0659\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 472.2068 - val_loss: 449.2766\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 449.3805 - val_loss: 429.5952\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 428.5040 - val_loss: 406.3349\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 408.4095 - val_loss: 389.4455\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 389.5956 - val_loss: 366.8482\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 372.6801 - val_loss: 350.2448\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 355.1123 - val_loss: 331.6918\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 339.2519 - val_loss: 317.9700\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 324.6862 - val_loss: 300.6703\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 311.2915 - val_loss: 289.8891\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 297.5027 - val_loss: 274.6626\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 285.9974 - val_loss: 262.2667\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 274.2297 - val_loss: 255.0181\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 263.4578 - val_loss: 241.3620\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 254.0987 - val_loss: 231.6149\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 244.9991 - val_loss: 222.8756\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 237.0166 - val_loss: 214.6113\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 227.9077 - val_loss: 206.7874\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 220.5100 - val_loss: 200.6140\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 213.5956 - val_loss: 192.7670\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 207.0979 - val_loss: 186.7453\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 200.7335 - val_loss: 181.9817\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 195.3153 - val_loss: 176.4948\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.1105 - val_loss: 171.0239\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.3536 - val_loss: 166.5592\n",
      "10/10 [==============================] - 0s 889us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 279010.1562 - val_loss: 225656.7188\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 178739.0469 - val_loss: 144190.6719\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 112683.7500 - val_loss: 88612.2969\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 66127.9219 - val_loss: 49390.5117\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 35324.3477 - val_loss: 25621.7832\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 17853.0469 - val_loss: 12680.9678\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 8835.4668 - val_loss: 6789.5122\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 5089.4458 - val_loss: 4389.2080\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3704.3088 - val_loss: 3624.2185\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3260.0496 - val_loss: 3372.9417\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3099.3591 - val_loss: 3220.5869\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2981.4800 - val_loss: 3106.9558\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2878.8281 - val_loss: 2998.3948\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2779.6824 - val_loss: 2896.1772\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2679.7656 - val_loss: 2794.8733\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2581.0740 - val_loss: 2694.5815\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2490.2544 - val_loss: 2598.9104\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2396.2908 - val_loss: 2507.8386\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2312.0474 - val_loss: 2420.2405\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2227.0127 - val_loss: 2332.0166\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2147.6133 - val_loss: 2248.3916\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2069.1194 - val_loss: 2168.7783\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1996.7458 - val_loss: 2091.9556\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1925.6643 - val_loss: 2018.0295\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1857.1593 - val_loss: 1947.8381\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1791.0820 - val_loss: 1878.4482\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1728.7191 - val_loss: 1813.2839\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1667.1246 - val_loss: 1752.6050\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1611.3619 - val_loss: 1691.1823\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1555.6810 - val_loss: 1633.5924\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1502.4113 - val_loss: 1576.7711\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1450.4005 - val_loss: 1524.3678\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1402.8132 - val_loss: 1474.1831\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1355.9309 - val_loss: 1425.9050\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1312.6348 - val_loss: 1379.7241\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1268.3417 - val_loss: 1335.8121\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1228.7147 - val_loss: 1292.0131\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1188.1163 - val_loss: 1251.2161\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1150.3326 - val_loss: 1210.4081\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1114.2435 - val_loss: 1171.9470\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1079.8376 - val_loss: 1136.3762\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1050.4064 - val_loss: 1101.5486\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1013.2714 - val_loss: 1069.2112\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 983.8039 - val_loss: 1037.0575\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 955.3476 - val_loss: 1004.8105\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 925.4094 - val_loss: 975.7004\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 897.8398 - val_loss: 947.4076\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 872.0917 - val_loss: 919.6174\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 846.6780 - val_loss: 893.3085\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 824.2159 - val_loss: 868.5632\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 5307.0020 - val_loss: 2362.0166\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2094.2419 - val_loss: 1774.2411\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1613.1055 - val_loss: 1436.9575\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1382.2323 - val_loss: 1236.2686\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1231.5968 - val_loss: 1105.7020\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1103.3702 - val_loss: 988.6926\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 991.1272 - val_loss: 901.5494\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 897.4709 - val_loss: 822.3433\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 818.7616 - val_loss: 752.0919\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 748.6723 - val_loss: 692.5037\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 685.6153 - val_loss: 636.7919\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 628.0651 - val_loss: 586.8103\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 578.4113 - val_loss: 539.1534\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 534.2580 - val_loss: 497.7592\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 492.8657 - val_loss: 467.5928\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 460.7539 - val_loss: 428.3231\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 426.8952 - val_loss: 399.2499\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 398.5658 - val_loss: 371.9694\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 372.2800 - val_loss: 347.7225\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 349.3246 - val_loss: 324.3132\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 326.3612 - val_loss: 303.8106\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 306.4370 - val_loss: 285.7271\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 289.8757 - val_loss: 268.8803\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 276.5068 - val_loss: 254.9553\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 260.8258 - val_loss: 244.9020\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 246.9588 - val_loss: 230.7465\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 235.0423 - val_loss: 220.3625\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 224.4913 - val_loss: 211.1076\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 215.5502 - val_loss: 203.1461\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 210.5210 - val_loss: 195.3078\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 199.2289 - val_loss: 187.3166\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.9439 - val_loss: 180.7490\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.9025 - val_loss: 174.2382\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.9567 - val_loss: 168.4249\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 174.5993 - val_loss: 163.4227\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.5742 - val_loss: 158.0925\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 164.5757 - val_loss: 156.0048\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 162.0698 - val_loss: 149.3667\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 157.0350 - val_loss: 145.5733\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 154.5583 - val_loss: 145.6425\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 150.1614 - val_loss: 138.8698\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.6830 - val_loss: 136.1420\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 143.6707 - val_loss: 132.4069\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 141.6529 - val_loss: 131.8294\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.4039 - val_loss: 128.8887\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 137.2797 - val_loss: 127.7558\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.8718 - val_loss: 122.6233\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 130.6108 - val_loss: 122.0549\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 130.3216 - val_loss: 123.5493\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 127.4819 - val_loss: 119.5001\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 23387.7559 - val_loss: 15380.6182\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 10777.0488 - val_loss: 6267.1260\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3681.4805 - val_loss: 1519.0095\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1035.8419 - val_loss: 770.3029\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 784.1826 - val_loss: 696.2089\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 698.2093 - val_loss: 621.8015\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 627.5139 - val_loss: 562.9177\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 566.7573 - val_loss: 512.9719\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 515.3294 - val_loss: 470.0858\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 471.4377 - val_loss: 433.6098\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 434.3257 - val_loss: 402.2879\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 402.8354 - val_loss: 376.0018\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 376.9030 - val_loss: 351.4561\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 354.3026 - val_loss: 331.6371\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 334.3851 - val_loss: 314.5307\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 317.9654 - val_loss: 299.7550\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 304.0176 - val_loss: 286.2340\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 290.4178 - val_loss: 275.0995\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 279.3397 - val_loss: 264.9622\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 270.7621 - val_loss: 256.2573\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 262.1539 - val_loss: 247.9991\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 253.4282 - val_loss: 241.3825\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 246.7085 - val_loss: 234.2447\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 240.1417 - val_loss: 228.1606\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 233.6962 - val_loss: 222.5552\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 228.7249 - val_loss: 217.5178\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 223.8432 - val_loss: 212.8585\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 219.1960 - val_loss: 208.2598\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 215.2238 - val_loss: 204.0801\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 211.0737 - val_loss: 200.0791\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 207.9460 - val_loss: 196.4528\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 202.8572 - val_loss: 193.4023\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 200.2996 - val_loss: 189.6387\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 196.6263 - val_loss: 186.4883\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.9093 - val_loss: 183.7167\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 189.8063 - val_loss: 180.8041\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 186.9494 - val_loss: 178.3674\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.8985 - val_loss: 175.1162\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 181.7083 - val_loss: 173.0748\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.8494 - val_loss: 170.2440\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.4894 - val_loss: 168.3497\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 174.6863 - val_loss: 166.1548\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 172.7564 - val_loss: 163.7171\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.4132 - val_loss: 161.2603\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 168.1977 - val_loss: 159.2207\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.5751 - val_loss: 157.3423\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.4694 - val_loss: 155.3372\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 162.4147 - val_loss: 152.9238\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 160.4320 - val_loss: 151.1990\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 158.4057 - val_loss: 149.2341\n",
      "10/10 [==============================] - 0s 1000us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 4967.6787 - val_loss: 4737.5122\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3667.4692 - val_loss: 3379.2092\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2672.1587 - val_loss: 2348.4912\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2006.4805 - val_loss: 1768.9973\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1556.2587 - val_loss: 1354.0292\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1268.9475 - val_loss: 1060.1803\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1038.0251 - val_loss: 909.1033\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 907.3773 - val_loss: 788.5742\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 810.2410 - val_loss: 691.3633\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 728.0240 - val_loss: 627.7764\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 666.7155 - val_loss: 579.2516\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 620.9023 - val_loss: 548.5495\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 583.1233 - val_loss: 504.7032\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 557.3524 - val_loss: 469.2994\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 513.8713 - val_loss: 441.5421\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 486.6643 - val_loss: 420.5948\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 467.4088 - val_loss: 397.6789\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 447.4211 - val_loss: 380.5442\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 433.4240 - val_loss: 367.9940\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 418.4871 - val_loss: 351.0029\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 403.8958 - val_loss: 340.0080\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 388.3727 - val_loss: 329.9618\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 386.1673 - val_loss: 314.3364\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 370.9763 - val_loss: 307.5605\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 356.0119 - val_loss: 296.1094\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 343.7842 - val_loss: 297.9638\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 335.8178 - val_loss: 288.7077\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 329.4136 - val_loss: 270.3926\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 317.2368 - val_loss: 263.2953\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 314.5118 - val_loss: 255.5976\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 302.9303 - val_loss: 254.4554\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 296.6022 - val_loss: 249.3748\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 291.0174 - val_loss: 242.6864\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 291.6808 - val_loss: 232.1416\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 278.4254 - val_loss: 225.7428\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 271.6580 - val_loss: 220.0924\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 263.0445 - val_loss: 214.9294\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 257.7537 - val_loss: 210.2797\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 254.5305 - val_loss: 208.5119\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 246.5159 - val_loss: 203.4404\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 243.8777 - val_loss: 197.0545\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 237.0632 - val_loss: 193.4983\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 232.7763 - val_loss: 189.1931\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 228.6168 - val_loss: 185.6356\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 223.1037 - val_loss: 184.3957\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 218.0510 - val_loss: 178.9381\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 212.7581 - val_loss: 176.3565\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 215.9052 - val_loss: 179.3598\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 210.2068 - val_loss: 175.8998\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 206.4302 - val_loss: 167.0330\n",
      "10/10 [==============================] - 0s 890us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 109451.9297 - val_loss: 57109.7422\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 32597.8945 - val_loss: 13895.1406\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 8513.8916 - val_loss: 5164.3408\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4832.1362 - val_loss: 4502.2891\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 4526.2158 - val_loss: 4304.8130\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 4288.4849 - val_loss: 4070.0486\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 4052.0552 - val_loss: 3862.5066\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3828.2080 - val_loss: 3659.5364\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3613.6270 - val_loss: 3454.6060\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3395.6606 - val_loss: 3263.4927\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3194.8088 - val_loss: 3077.8062\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3001.6108 - val_loss: 2899.8123\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2819.9404 - val_loss: 2725.9709\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2643.2808 - val_loss: 2570.4958\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2486.7810 - val_loss: 2418.3369\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2333.8765 - val_loss: 2277.4075\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2188.6738 - val_loss: 2146.8533\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2058.5098 - val_loss: 2023.2349\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1935.0940 - val_loss: 1902.3246\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1817.9834 - val_loss: 1797.1050\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1711.9108 - val_loss: 1697.2231\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1615.4929 - val_loss: 1600.5941\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1525.1620 - val_loss: 1512.5758\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1434.1158 - val_loss: 1430.1300\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1355.6444 - val_loss: 1354.7054\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1282.6150 - val_loss: 1285.4741\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1214.5790 - val_loss: 1218.6584\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1160.9634 - val_loss: 1154.9504\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1096.0546 - val_loss: 1097.3599\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1040.6835 - val_loss: 1045.1056\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 988.7415 - val_loss: 993.8176\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 943.5382 - val_loss: 947.1455\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 898.0475 - val_loss: 903.3286\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 859.6529 - val_loss: 862.0503\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 821.1598 - val_loss: 825.2763\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 786.1237 - val_loss: 789.0551\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 752.6196 - val_loss: 755.3438\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 723.2510 - val_loss: 723.7700\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 692.6356 - val_loss: 692.5632\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 665.9475 - val_loss: 664.7120\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 640.1702 - val_loss: 637.6224\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 615.6282 - val_loss: 613.1953\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 592.7484 - val_loss: 589.1260\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 572.0472 - val_loss: 566.2534\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 550.3597 - val_loss: 545.8912\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 531.3890 - val_loss: 526.7069\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 513.9675 - val_loss: 506.9725\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 495.4485 - val_loss: 487.7908\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 478.5760 - val_loss: 471.6886\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 463.0893 - val_loss: 453.7932\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 14563.2451 - val_loss: 4708.8340\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2695.3699 - val_loss: 1906.0527\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1768.1205 - val_loss: 1506.2666\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1384.2639 - val_loss: 1240.4756\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1139.0908 - val_loss: 1018.1823\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 933.6902 - val_loss: 835.6881\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 761.4371 - val_loss: 679.9305\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 619.6104 - val_loss: 556.8928\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 508.1405 - val_loss: 462.2215\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 420.6448 - val_loss: 391.9369\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 356.3459 - val_loss: 338.2843\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 304.9986 - val_loss: 293.2386\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 264.1610 - val_loss: 262.9085\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 236.4390 - val_loss: 239.3256\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 211.9677 - val_loss: 219.9686\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.4159 - val_loss: 205.7760\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.9004 - val_loss: 196.3079\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 171.6985 - val_loss: 184.8105\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 161.8413 - val_loss: 177.4360\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 155.4050 - val_loss: 170.1738\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 149.5661 - val_loss: 168.3488\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 144.6743 - val_loss: 162.7941\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 140.3086 - val_loss: 156.8479\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.4631 - val_loss: 153.5264\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.5000 - val_loss: 151.2794\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 131.3433 - val_loss: 154.9632\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 129.6082 - val_loss: 146.9465\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.2191 - val_loss: 146.3490\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.5182 - val_loss: 144.1796\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 122.7624 - val_loss: 142.0097\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.8054 - val_loss: 140.4198\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 119.9169 - val_loss: 141.6512\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 118.0121 - val_loss: 138.8840\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 117.1032 - val_loss: 139.1780\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 115.7749 - val_loss: 136.2800\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 114.7938 - val_loss: 137.1375\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 114.4598 - val_loss: 135.9212\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 114.2657 - val_loss: 135.3164\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 112.4383 - val_loss: 132.5896\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 112.3793 - val_loss: 135.8755\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 110.5754 - val_loss: 139.0392\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 110.9982 - val_loss: 132.3244\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 109.5573 - val_loss: 133.4867\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 108.6714 - val_loss: 131.7818\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 109.8275 - val_loss: 131.0083\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 108.6592 - val_loss: 130.1651\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 107.4825 - val_loss: 131.0363\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 107.2600 - val_loss: 129.1858\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 108.4460 - val_loss: 131.5138\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 107.3550 - val_loss: 129.1268\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 5447.4956 - val_loss: 2605.0103\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2153.9001 - val_loss: 2310.6621\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1799.6829 - val_loss: 2087.9968\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1581.3330 - val_loss: 1835.1721\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1417.2953 - val_loss: 1649.2509\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1255.4550 - val_loss: 1477.4261\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1125.7791 - val_loss: 1322.3777\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1009.3033 - val_loss: 1187.9816\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 911.2968 - val_loss: 1075.0676\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 815.9830 - val_loss: 968.5233\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 739.8568 - val_loss: 873.8519\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 660.9573 - val_loss: 782.6818\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 603.1234 - val_loss: 701.9909\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 539.2866 - val_loss: 637.3715\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 489.1536 - val_loss: 574.8216\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 452.4753 - val_loss: 523.8165\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 413.7450 - val_loss: 479.2488\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 377.6440 - val_loss: 443.9153\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 349.6657 - val_loss: 408.2314\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 322.8168 - val_loss: 372.8807\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 296.0703 - val_loss: 340.2299\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 276.9026 - val_loss: 315.8174\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 264.7544 - val_loss: 302.7322\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 243.7033 - val_loss: 277.0897\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 228.9221 - val_loss: 259.8307\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 219.8791 - val_loss: 247.1662\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 208.2674 - val_loss: 235.4002\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.5723 - val_loss: 223.9066\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 191.5281 - val_loss: 214.2994\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 183.5522 - val_loss: 204.4578\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.4308 - val_loss: 194.8215\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 170.4473 - val_loss: 188.7966\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 166.8246 - val_loss: 182.2497\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.3751 - val_loss: 179.1912\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 157.9780 - val_loss: 172.4786\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 154.4220 - val_loss: 168.6345\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 150.3970 - val_loss: 166.4092\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.1622 - val_loss: 162.0708\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 147.1888 - val_loss: 157.6567\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.7173 - val_loss: 154.9284\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.7889 - val_loss: 153.0948\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 141.3052 - val_loss: 150.5178\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.1476 - val_loss: 150.1018\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 137.0198 - val_loss: 146.0272\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 134.5830 - val_loss: 145.9403\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.2270 - val_loss: 143.0592\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 132.8683 - val_loss: 141.2989\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.7238 - val_loss: 139.7226\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.1893 - val_loss: 138.4071\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 135.1039 - val_loss: 143.7010\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 7804.6440 - val_loss: 1596.0226\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1766.7056 - val_loss: 1298.6339\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1279.6654 - val_loss: 1092.2095\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1081.3174 - val_loss: 910.5524\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 891.9975 - val_loss: 761.6189\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 742.8986 - val_loss: 629.8672\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 616.6914 - val_loss: 527.1553\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 519.8188 - val_loss: 443.6866\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 436.8196 - val_loss: 375.7998\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 376.5738 - val_loss: 327.5317\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 323.4659 - val_loss: 282.3840\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 283.5442 - val_loss: 250.7914\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 257.0700 - val_loss: 222.5781\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 227.4476 - val_loss: 204.6721\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 209.0445 - val_loss: 186.4189\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.3072 - val_loss: 174.3161\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.2054 - val_loss: 163.3343\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 173.0110 - val_loss: 155.2391\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.6961 - val_loss: 148.0556\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 159.7004 - val_loss: 142.3605\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 153.3539 - val_loss: 137.1144\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 149.1589 - val_loss: 133.0290\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 145.4709 - val_loss: 131.9343\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 141.3737 - val_loss: 128.2463\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 137.5429 - val_loss: 124.8164\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 136.2415 - val_loss: 122.6632\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.2850 - val_loss: 119.9181\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.0298 - val_loss: 121.1461\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 130.6350 - val_loss: 117.4401\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 126.4498 - val_loss: 116.0741\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.7472 - val_loss: 115.4046\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 127.2833 - val_loss: 113.6188\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.3493 - val_loss: 112.8700\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.4998 - val_loss: 112.5031\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 121.8648 - val_loss: 111.4982\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 119.7312 - val_loss: 112.0401\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 118.1993 - val_loss: 111.5825\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 122.2663 - val_loss: 118.7142\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.2064 - val_loss: 110.1237\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 117.6653 - val_loss: 109.8769\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 116.7330 - val_loss: 111.4149\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 118.4912 - val_loss: 110.2906\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 119.2011 - val_loss: 109.7542\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 115.8883 - val_loss: 109.1834\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 115.2503 - val_loss: 109.1177\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 118.0940 - val_loss: 110.9771\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 114.6455 - val_loss: 109.7086\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 115.9555 - val_loss: 110.3948\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 114.8186 - val_loss: 114.6479\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 115.0046 - val_loss: 108.7020\n",
      "10/10 [==============================] - 0s 999us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 189034.4688 - val_loss: 107477.8828\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 66012.9219 - val_loss: 29523.4492\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 15764.1953 - val_loss: 5486.5078\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2957.6367 - val_loss: 1405.0770\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1184.8923 - val_loss: 1167.8829\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1112.0543 - val_loss: 1165.0514\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1101.3739 - val_loss: 1147.7642\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1087.8345 - val_loss: 1135.3090\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1074.7175 - val_loss: 1122.8335\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1062.4316 - val_loss: 1107.6028\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1049.3186 - val_loss: 1095.0066\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1035.3068 - val_loss: 1082.5864\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1022.3016 - val_loss: 1068.8486\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1011.1654 - val_loss: 1054.3234\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 997.4667 - val_loss: 1042.8391\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 981.3856 - val_loss: 1027.7544\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 966.5092 - val_loss: 1012.6122\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 953.4144 - val_loss: 996.3907\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 937.5530 - val_loss: 979.9683\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 926.8118 - val_loss: 962.3195\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 902.8234 - val_loss: 940.1336\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 879.6868 - val_loss: 925.8276\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 861.4680 - val_loss: 911.3567\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 850.7054 - val_loss: 895.2018\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 834.0932 - val_loss: 881.7848\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 817.4297 - val_loss: 868.5681\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 799.4728 - val_loss: 854.9144\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 780.4496 - val_loss: 836.3288\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 763.0596 - val_loss: 823.6314\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 747.6246 - val_loss: 806.2676\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 730.6485 - val_loss: 787.8274\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 713.9120 - val_loss: 771.0924\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 698.1795 - val_loss: 754.5507\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 682.2102 - val_loss: 737.7557\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 662.7536 - val_loss: 721.1609\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 649.4789 - val_loss: 698.7129\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 635.8568 - val_loss: 682.5342\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 617.9446 - val_loss: 662.6921\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 599.7895 - val_loss: 644.5512\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 569.0619 - val_loss: 597.7564\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 528.0936 - val_loss: 554.0494\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 480.8038 - val_loss: 507.6375\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 428.3113 - val_loss: 446.3157\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 378.9230 - val_loss: 396.3547\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 336.6632 - val_loss: 360.7964\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 303.0655 - val_loss: 314.9527\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 262.8891 - val_loss: 276.6117\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 237.9526 - val_loss: 251.6557\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 212.7742 - val_loss: 218.9834\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 189.4233 - val_loss: 205.3233\n",
      "10/10 [==============================] - 0s 889us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 159429.6094 - val_loss: 119411.4844\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 89998.0234 - val_loss: 60625.7227\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 40246.5781 - val_loss: 19969.1641\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 10452.9893 - val_loss: 3717.6650\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1856.7637 - val_loss: 1170.3741\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 935.0864 - val_loss: 1105.5424\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 907.7195 - val_loss: 1063.8278\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 877.0058 - val_loss: 1022.7205\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 848.2131 - val_loss: 988.2154\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 820.4067 - val_loss: 954.2177\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 796.1047 - val_loss: 919.1306\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 768.8651 - val_loss: 885.2673\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 743.1252 - val_loss: 852.1629\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 718.0914 - val_loss: 818.8081\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 693.7686 - val_loss: 788.8729\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 670.8099 - val_loss: 760.8901\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 649.5367 - val_loss: 731.8663\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 628.2933 - val_loss: 706.6667\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 609.4093 - val_loss: 679.9872\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 589.8251 - val_loss: 657.4238\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 571.4068 - val_loss: 632.3903\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 553.6424 - val_loss: 610.1981\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 537.1646 - val_loss: 589.2397\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 521.6877 - val_loss: 569.7541\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 505.8404 - val_loss: 552.1484\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 490.2328 - val_loss: 531.4484\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 475.9426 - val_loss: 517.3840\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 461.8809 - val_loss: 497.7629\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 447.8332 - val_loss: 481.6913\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 435.8713 - val_loss: 466.4250\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 421.6874 - val_loss: 450.2137\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 410.7676 - val_loss: 437.6264\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 398.6968 - val_loss: 420.8642\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 385.1118 - val_loss: 410.6098\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 374.4833 - val_loss: 394.9328\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 363.4458 - val_loss: 382.7980\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 352.2026 - val_loss: 368.9451\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 341.4563 - val_loss: 357.9935\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 332.3429 - val_loss: 346.9989\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 322.7380 - val_loss: 335.8916\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 312.4782 - val_loss: 325.3166\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 303.2161 - val_loss: 314.1085\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 295.4495 - val_loss: 305.5591\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 285.1245 - val_loss: 296.8160\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 277.0493 - val_loss: 286.3823\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 269.1938 - val_loss: 279.9360\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 261.6487 - val_loss: 269.7415\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 254.1740 - val_loss: 262.6743\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 246.7831 - val_loss: 254.1500\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 239.7413 - val_loss: 247.1626\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 319390.7500 - val_loss: 218637.7969\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 159661.0625 - val_loss: 91216.8281\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 60772.4219 - val_loss: 29448.9766\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 19427.5703 - val_loss: 10603.0791\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 8410.1855 - val_loss: 7623.5298\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 6653.3867 - val_loss: 7306.3486\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 6292.2329 - val_loss: 6924.7632\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 5954.6519 - val_loss: 6586.8379\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 5648.6851 - val_loss: 6212.0781\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 5339.9658 - val_loss: 5812.2964\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 5032.5483 - val_loss: 5502.7700\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4740.2402 - val_loss: 5135.7002\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 4460.3457 - val_loss: 4838.9658\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 4192.5435 - val_loss: 4505.5508\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3930.1174 - val_loss: 4219.6191\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3694.0828 - val_loss: 3964.4219\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3462.4546 - val_loss: 3691.1736\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3246.1833 - val_loss: 3463.8386\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3043.8096 - val_loss: 3239.5088\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2855.7217 - val_loss: 3030.8794\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2681.5601 - val_loss: 2842.1775\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2519.4290 - val_loss: 2654.8850\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2360.7998 - val_loss: 2483.8521\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2221.8423 - val_loss: 2333.2612\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2093.8008 - val_loss: 2185.5154\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1971.5981 - val_loss: 2054.5596\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1861.7942 - val_loss: 1942.0530\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1757.5750 - val_loss: 1827.0127\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1666.3390 - val_loss: 1728.1158\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1578.3138 - val_loss: 1631.9324\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1495.3751 - val_loss: 1534.5068\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1420.6841 - val_loss: 1468.2974\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1350.4609 - val_loss: 1395.5834\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1285.9321 - val_loss: 1316.1071\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1226.7495 - val_loss: 1251.8011\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1172.1158 - val_loss: 1203.5042\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1123.0381 - val_loss: 1144.3599\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1077.2102 - val_loss: 1098.4473\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1036.0453 - val_loss: 1051.7377\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 996.3162 - val_loss: 1010.9463\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 956.5181 - val_loss: 974.9651\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 921.9587 - val_loss: 938.1327\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 889.3259 - val_loss: 901.2792\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 858.2020 - val_loss: 868.6846\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 832.3824 - val_loss: 841.4191\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 802.1755 - val_loss: 816.9183\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 778.1997 - val_loss: 783.2198\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 758.1623 - val_loss: 758.5515\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 731.7661 - val_loss: 736.3131\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 710.1072 - val_loss: 712.0566\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 111525.9844 - val_loss: 57239.2031\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 35988.0039 - val_loss: 15073.5303\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 12903.3662 - val_loss: 8414.8594\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 9522.3545 - val_loss: 7633.0552\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 8491.8086 - val_loss: 6744.8506\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 7591.8999 - val_loss: 6099.6143\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 6847.7808 - val_loss: 5518.4014\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 6192.9624 - val_loss: 5020.6265\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 5554.7407 - val_loss: 4541.3594\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 5008.5986 - val_loss: 4153.5869\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4519.0820 - val_loss: 3761.4556\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 4072.8838 - val_loss: 3451.7512\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3680.8135 - val_loss: 3155.4324\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3336.1067 - val_loss: 2898.1663\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3024.5447 - val_loss: 2676.2117\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2756.3064 - val_loss: 2444.6204\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2516.2407 - val_loss: 2270.2041\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2294.8628 - val_loss: 2102.9507\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2097.0098 - val_loss: 1967.3279\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1923.2441 - val_loss: 1792.7992\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1768.6321 - val_loss: 1668.1329\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1630.9121 - val_loss: 1548.2808\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1501.4054 - val_loss: 1456.6825\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1396.8467 - val_loss: 1354.0380\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1290.1616 - val_loss: 1275.7769\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1197.2900 - val_loss: 1174.2312\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1114.0015 - val_loss: 1131.5741\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1042.1647 - val_loss: 1032.6084\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 974.0643 - val_loss: 977.3999\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 913.4860 - val_loss: 919.6612\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 858.6072 - val_loss: 863.4081\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 808.9395 - val_loss: 824.6900\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 765.3796 - val_loss: 778.2252\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 724.7498 - val_loss: 755.1931\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 697.0484 - val_loss: 708.3912\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 655.5607 - val_loss: 680.8260\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 630.8704 - val_loss: 655.6771\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 599.5201 - val_loss: 626.8148\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 573.1362 - val_loss: 604.7559\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 556.8808 - val_loss: 579.0601\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 532.9788 - val_loss: 558.5413\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 513.0277 - val_loss: 540.6289\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 498.4084 - val_loss: 524.5714\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 482.6954 - val_loss: 514.5551\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 472.8207 - val_loss: 504.0564\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 457.2116 - val_loss: 479.5229\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 438.8989 - val_loss: 463.4333\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 429.7579 - val_loss: 467.9284\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 415.1406 - val_loss: 440.9314\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 401.7938 - val_loss: 428.2100\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 37879.7383 - val_loss: 16198.5244\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 7339.1553 - val_loss: 3424.1067\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2870.5503 - val_loss: 2856.5759\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2603.3206 - val_loss: 2632.8528\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2394.4084 - val_loss: 2454.7458\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2214.2498 - val_loss: 2266.5796\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2043.2214 - val_loss: 2093.3225\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1877.3136 - val_loss: 1928.8488\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1723.2167 - val_loss: 1775.4938\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1583.6160 - val_loss: 1631.6522\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1448.9933 - val_loss: 1497.0336\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1330.6696 - val_loss: 1378.1792\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1222.7039 - val_loss: 1272.6581\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1125.3571 - val_loss: 1169.9692\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1039.6638 - val_loss: 1082.4650\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 953.1500 - val_loss: 1000.7137\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 883.8599 - val_loss: 928.8347\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 819.6392 - val_loss: 866.5402\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 765.6215 - val_loss: 807.6915\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 714.8945 - val_loss: 756.9689\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 670.1445 - val_loss: 709.0298\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 630.0399 - val_loss: 667.7332\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 596.9839 - val_loss: 632.4041\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 563.6921 - val_loss: 598.8959\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 536.5139 - val_loss: 568.2986\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 511.4915 - val_loss: 541.2889\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 492.6514 - val_loss: 517.3030\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 469.5656 - val_loss: 495.6817\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 451.0385 - val_loss: 475.6838\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 435.1859 - val_loss: 456.6094\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 420.2994 - val_loss: 441.2289\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 408.1323 - val_loss: 425.4367\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 394.9764 - val_loss: 411.1238\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 384.8094 - val_loss: 397.9496\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 372.3919 - val_loss: 386.3061\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 362.6332 - val_loss: 375.1000\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 353.9223 - val_loss: 363.8083\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 345.1073 - val_loss: 354.3710\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 336.5813 - val_loss: 344.9163\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 329.0970 - val_loss: 335.5027\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 321.1724 - val_loss: 326.7594\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 315.1142 - val_loss: 319.5130\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 309.5088 - val_loss: 312.0592\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 301.1435 - val_loss: 303.4781\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 294.9710 - val_loss: 297.9167\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 290.6226 - val_loss: 289.6125\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 283.6279 - val_loss: 283.0018\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 278.4061 - val_loss: 276.9836\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 272.1257 - val_loss: 270.9660\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 267.1181 - val_loss: 265.2620\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 734.6033 - val_loss: 496.6351\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 411.2571 - val_loss: 293.2090\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 271.5591 - val_loss: 239.8832\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 236.6674 - val_loss: 213.4223\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 214.8957 - val_loss: 194.4991\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 189.4089 - val_loss: 179.4320\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.1449 - val_loss: 161.8567\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 157.2165 - val_loss: 149.6140\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 151.6707 - val_loss: 142.2918\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.6790 - val_loss: 134.5056\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.3801 - val_loss: 138.4540\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 132.1725 - val_loss: 126.8391\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.9408 - val_loss: 136.5937\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.3665 - val_loss: 124.0618\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.4131 - val_loss: 122.7763\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 119.8378 - val_loss: 124.4109\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 122.2597 - val_loss: 131.9508\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.2734 - val_loss: 115.2871\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 114.9717 - val_loss: 114.7608\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 125.4094 - val_loss: 120.7898\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 113.7578 - val_loss: 119.9114\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 114.7787 - val_loss: 111.0158\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 114.3002 - val_loss: 110.4434\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 113.0258 - val_loss: 110.1232\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 118.1960 - val_loss: 121.1323\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 114.3382 - val_loss: 111.9774\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 112.8385 - val_loss: 110.5309\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 114.6265 - val_loss: 110.2543\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 110.6464 - val_loss: 112.2421\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 111.9495 - val_loss: 114.7469\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 110.4155 - val_loss: 105.4038\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 110.6073 - val_loss: 112.6269\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 110.5419 - val_loss: 105.2931\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 107.9764 - val_loss: 104.3690\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 111.8191 - val_loss: 114.2099\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 109.8239 - val_loss: 109.6026\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 111.5755 - val_loss: 115.5627\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 112.1656 - val_loss: 108.8574\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 115.7523 - val_loss: 109.4827\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 108.6309 - val_loss: 102.0600\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 111.0538 - val_loss: 104.4327\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 113.1053 - val_loss: 113.6367\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 108.3095 - val_loss: 117.3618\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 113.9999 - val_loss: 102.0823\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 114.9429 - val_loss: 100.4031\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 114.0304 - val_loss: 108.9017\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 112.5384 - val_loss: 102.9437\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 107.4732 - val_loss: 100.2753\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 108.9617 - val_loss: 99.7785\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 109.3791 - val_loss: 101.8013\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 386906.9375 - val_loss: 280808.9375\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 221797.1875 - val_loss: 151823.2812\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 117084.5391 - val_loss: 75168.8984\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 56849.0312 - val_loss: 35349.2852\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 27263.7051 - val_loss: 17777.0586\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 14853.2676 - val_loss: 12045.3135\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 10816.9551 - val_loss: 10578.8281\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 9707.1182 - val_loss: 10144.8760\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 9272.6826 - val_loss: 9841.9102\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 8934.5908 - val_loss: 9520.0020\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 8603.6348 - val_loss: 9175.6777\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 8272.6348 - val_loss: 8780.9512\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 7931.9888 - val_loss: 8402.1064\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 7599.5781 - val_loss: 8042.0938\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 7261.5781 - val_loss: 7670.4043\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 6932.8560 - val_loss: 7293.0972\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 6603.9814 - val_loss: 6960.9609\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 6289.7227 - val_loss: 6641.8125\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 5991.9585 - val_loss: 6304.0044\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 5695.4419 - val_loss: 5972.8784\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 5419.8486 - val_loss: 5681.5972\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 5145.9712 - val_loss: 5372.6470\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 4871.2920 - val_loss: 5088.0132\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 4607.8838 - val_loss: 4771.2183\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4341.7598 - val_loss: 4484.0117\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 4081.3655 - val_loss: 4217.0444\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3834.1360 - val_loss: 3973.4746\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3596.2024 - val_loss: 3723.6846\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3373.0500 - val_loss: 3478.6274\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3165.3291 - val_loss: 3262.9258\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2968.2344 - val_loss: 3072.6201\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2783.5935 - val_loss: 2883.0881\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2613.2385 - val_loss: 2713.1812\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2462.6050 - val_loss: 2562.2622\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2308.2310 - val_loss: 2418.3074\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2179.1699 - val_loss: 2285.2224\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2056.2976 - val_loss: 2163.8857\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1945.6012 - val_loss: 2049.6255\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1834.8887 - val_loss: 1948.4713\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1739.1210 - val_loss: 1849.3331\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1650.0066 - val_loss: 1752.5178\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1566.5085 - val_loss: 1672.4755\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1490.9308 - val_loss: 1594.2915\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1420.9717 - val_loss: 1522.9177\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1356.9528 - val_loss: 1454.0052\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1298.5344 - val_loss: 1393.3304\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1240.0052 - val_loss: 1333.7854\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1187.1831 - val_loss: 1274.6261\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1134.6359 - val_loss: 1223.2211\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1088.0767 - val_loss: 1171.0443\n",
      "10/10 [==============================] - 0s 966us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 88111.7891 - val_loss: 53938.4570\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 38216.8359 - val_loss: 22016.3438\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 14567.1523 - val_loss: 6566.6489\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 5290.8032 - val_loss: 4163.1299\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4199.3945 - val_loss: 3477.9995\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3582.1196 - val_loss: 3016.3850\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3151.1575 - val_loss: 2652.6663\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2778.0857 - val_loss: 2335.6738\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2456.0400 - val_loss: 2087.1462\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2192.5134 - val_loss: 1856.5918\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1958.5408 - val_loss: 1679.8435\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1768.9331 - val_loss: 1513.6284\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1582.6509 - val_loss: 1363.5314\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1415.1206 - val_loss: 1235.4203\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1274.3636 - val_loss: 1123.4646\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1156.7246 - val_loss: 1034.5752\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1055.4092 - val_loss: 948.7380\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 973.5978 - val_loss: 880.8746\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 897.4951 - val_loss: 821.6740\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 834.9152 - val_loss: 771.2061\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 777.7284 - val_loss: 719.5420\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 729.1038 - val_loss: 681.7932\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 685.7440 - val_loss: 641.7589\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 648.0098 - val_loss: 609.1620\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 611.9608 - val_loss: 579.9416\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 582.1108 - val_loss: 551.5344\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 553.3173 - val_loss: 530.9061\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 527.3411 - val_loss: 505.0795\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 505.8383 - val_loss: 483.6519\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 482.8399 - val_loss: 467.3093\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 463.8699 - val_loss: 446.5691\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 445.6753 - val_loss: 430.5460\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 428.7273 - val_loss: 413.1660\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 412.2547 - val_loss: 398.4442\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 395.8900 - val_loss: 383.6049\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 381.5351 - val_loss: 372.7368\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 367.9636 - val_loss: 357.4320\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 355.7499 - val_loss: 345.2312\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 344.5347 - val_loss: 333.8947\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 333.5807 - val_loss: 323.8807\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 321.2238 - val_loss: 312.9504\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 313.4050 - val_loss: 304.2982\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 302.1725 - val_loss: 293.7097\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 291.5623 - val_loss: 282.9395\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 282.6417 - val_loss: 273.4533\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 272.7960 - val_loss: 266.7215\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 264.7300 - val_loss: 256.7374\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 256.7999 - val_loss: 249.4560\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 249.8289 - val_loss: 244.9454\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 242.2449 - val_loss: 234.6594\n",
      "10/10 [==============================] - 0s 890us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 12468.4893 - val_loss: 4161.7939\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2106.9758 - val_loss: 1415.8163\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1304.7566 - val_loss: 1273.8912\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1118.3707 - val_loss: 1071.0640\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 932.5067 - val_loss: 847.0251\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 789.5922 - val_loss: 680.3157\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 682.2530 - val_loss: 600.1938\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 610.3359 - val_loss: 551.8772\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 569.9450 - val_loss: 513.3406\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 534.3900 - val_loss: 478.9362\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 501.6589 - val_loss: 453.0186\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 477.1052 - val_loss: 426.4102\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 452.3597 - val_loss: 403.2285\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 432.3522 - val_loss: 382.8009\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 411.4922 - val_loss: 363.5500\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 394.2778 - val_loss: 345.2458\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 370.8697 - val_loss: 322.2832\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 345.2246 - val_loss: 286.8633\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 303.3144 - val_loss: 255.5774\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 269.5740 - val_loss: 229.1749\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 242.5365 - val_loss: 220.6797\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 225.0692 - val_loss: 210.7653\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 205.6102 - val_loss: 188.1997\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 191.9154 - val_loss: 178.7870\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180.1501 - val_loss: 168.7936\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.6346 - val_loss: 170.1636\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.5079 - val_loss: 151.9900\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 150.9289 - val_loss: 145.4446\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 146.1337 - val_loss: 142.3326\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 139.7204 - val_loss: 134.1211\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 133.2887 - val_loss: 129.1491\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 129.7730 - val_loss: 125.6095\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 125.9528 - val_loss: 121.9334\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 125.6162 - val_loss: 119.3172\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 122.9905 - val_loss: 117.2120\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 117.4683 - val_loss: 114.7483\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 115.4998 - val_loss: 111.5064\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 113.5080 - val_loss: 109.9557\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 111.2435 - val_loss: 108.1043\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 109.9117 - val_loss: 107.5369\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 108.3038 - val_loss: 106.5880\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 107.0966 - val_loss: 103.9673\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 106.1488 - val_loss: 103.0703\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 105.0883 - val_loss: 103.2894\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 104.0257 - val_loss: 101.0650\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 102.3029 - val_loss: 104.5687\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 101.8814 - val_loss: 99.4765\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 100.7761 - val_loss: 98.9305\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 99.7502 - val_loss: 97.7828\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 99.4120 - val_loss: 96.8620\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 39728.2383 - val_loss: 25086.5000\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 14629.8076 - val_loss: 5304.4639\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2849.0034 - val_loss: 2034.5061\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2061.6731 - val_loss: 1903.2698\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1878.8308 - val_loss: 1754.0388\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1760.6903 - val_loss: 1641.1621\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1651.0487 - val_loss: 1528.9180\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1547.0247 - val_loss: 1414.1273\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1439.5402 - val_loss: 1318.1539\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1341.0648 - val_loss: 1210.7848\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1243.1626 - val_loss: 1119.0603\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1153.8473 - val_loss: 1035.3093\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1070.9883 - val_loss: 953.7233\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 994.2728 - val_loss: 885.1887\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 925.0575 - val_loss: 820.2731\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 858.0636 - val_loss: 757.2686\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 799.4891 - val_loss: 705.5264\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 744.3467 - val_loss: 653.8385\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 699.6231 - val_loss: 613.6606\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 652.6017 - val_loss: 572.5456\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 615.3953 - val_loss: 538.0203\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 579.3782 - val_loss: 507.7057\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 545.6786 - val_loss: 478.5599\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 515.1195 - val_loss: 459.5393\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 490.2936 - val_loss: 433.5840\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 472.4171 - val_loss: 423.3839\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 449.1938 - val_loss: 396.9015\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 428.0170 - val_loss: 381.9153\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 411.6633 - val_loss: 368.4843\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 397.0362 - val_loss: 360.7336\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 384.1993 - val_loss: 346.3043\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 371.0664 - val_loss: 341.7874\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 361.3562 - val_loss: 327.3102\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 358.9921 - val_loss: 324.2279\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 342.0811 - val_loss: 321.5268\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 331.6826 - val_loss: 306.3000\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 325.2504 - val_loss: 300.8126\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 320.0872 - val_loss: 299.0439\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 310.8535 - val_loss: 292.7765\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 302.7420 - val_loss: 286.1117\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 297.1752 - val_loss: 281.7021\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 290.1139 - val_loss: 277.5788\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 285.4798 - val_loss: 272.1355\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 279.2675 - val_loss: 268.5418\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 275.7217 - val_loss: 264.2391\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 271.3426 - val_loss: 261.5315\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 264.2494 - val_loss: 256.6194\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 260.0943 - val_loss: 256.8097\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 255.7735 - val_loss: 249.5918\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 249.6142 - val_loss: 247.2300\n",
      "10/10 [==============================] - 0s 999us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 42483.7852 - val_loss: 19480.0039\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 10041.3213 - val_loss: 3958.2407\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3176.3542 - val_loss: 2841.3813\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2789.1941 - val_loss: 2582.6904\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2555.0483 - val_loss: 2396.1233\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2377.2075 - val_loss: 2214.3457\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2209.6536 - val_loss: 2062.0852\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2064.6570 - val_loss: 1917.7898\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1934.4655 - val_loss: 1792.7913\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1819.1786 - val_loss: 1675.0052\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1703.8037 - val_loss: 1576.6547\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1611.1045 - val_loss: 1474.6301\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1518.4315 - val_loss: 1389.3293\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1434.4388 - val_loss: 1311.6512\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1352.3922 - val_loss: 1235.8740\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1282.2283 - val_loss: 1160.5829\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1210.9761 - val_loss: 1095.8765\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1145.6633 - val_loss: 1034.7385\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1082.1860 - val_loss: 974.6647\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1021.9404 - val_loss: 918.3026\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 965.4074 - val_loss: 865.3082\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 911.4226 - val_loss: 813.0827\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 858.0151 - val_loss: 768.4183\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 813.7595 - val_loss: 724.3076\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 766.6832 - val_loss: 676.8847\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 721.2770 - val_loss: 646.3412\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 680.7662 - val_loss: 602.0330\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 640.4105 - val_loss: 568.3272\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 603.3838 - val_loss: 534.6093\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 568.4628 - val_loss: 505.0554\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 537.8204 - val_loss: 477.7653\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 507.6506 - val_loss: 448.5719\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 478.9679 - val_loss: 424.4778\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 454.1275 - val_loss: 405.1041\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 429.5815 - val_loss: 381.0796\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 406.6938 - val_loss: 364.7305\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 384.4912 - val_loss: 341.9149\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 365.7368 - val_loss: 327.8591\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 348.1393 - val_loss: 314.4924\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 331.3412 - val_loss: 298.6895\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 316.5643 - val_loss: 285.4854\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 302.0051 - val_loss: 276.2157\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 288.9090 - val_loss: 265.0671\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 276.7633 - val_loss: 254.5484\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 267.0464 - val_loss: 249.7386\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 256.0193 - val_loss: 233.7448\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 246.9797 - val_loss: 232.3086\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 237.5232 - val_loss: 223.2985\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 229.8141 - val_loss: 215.8460\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 221.1227 - val_loss: 212.5429\n",
      "10/10 [==============================] - 0s 889us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 38641.5898 - val_loss: 25305.7090\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 14666.5107 - val_loss: 8889.2168\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 4548.1650 - val_loss: 3259.0100\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1944.0863 - val_loss: 2107.8682\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1530.8812 - val_loss: 1919.3500\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1451.2538 - val_loss: 1826.7419\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1379.3801 - val_loss: 1744.1798\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1314.7318 - val_loss: 1671.2839\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1251.6119 - val_loss: 1587.8732\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1193.4362 - val_loss: 1516.5139\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1139.4780 - val_loss: 1452.6932\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1087.6194 - val_loss: 1396.4017\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1040.1718 - val_loss: 1330.8004\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 992.4894 - val_loss: 1279.1283\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 949.7961 - val_loss: 1226.6272\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 908.3325 - val_loss: 1176.7927\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 871.5441 - val_loss: 1137.6586\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 833.3019 - val_loss: 1083.1543\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 799.1216 - val_loss: 1044.3623\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 765.6401 - val_loss: 1004.4674\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 734.9445 - val_loss: 964.3303\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 705.6324 - val_loss: 928.3932\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 678.7253 - val_loss: 894.8572\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 652.6683 - val_loss: 861.1679\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 626.4620 - val_loss: 835.8637\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 603.0890 - val_loss: 806.3651\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 581.8622 - val_loss: 779.2605\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 560.8335 - val_loss: 755.8434\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 540.6449 - val_loss: 728.6710\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 522.6997 - val_loss: 705.6130\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 505.1090 - val_loss: 689.0103\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 488.7374 - val_loss: 662.3358\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 472.4091 - val_loss: 645.9760\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 458.1186 - val_loss: 629.0494\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 444.3613 - val_loss: 610.3104\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 431.4521 - val_loss: 593.9202\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 419.4502 - val_loss: 575.1590\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 408.0285 - val_loss: 564.8613\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 396.3777 - val_loss: 549.0316\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 385.5692 - val_loss: 533.5870\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 375.7397 - val_loss: 519.2076\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 365.7965 - val_loss: 505.1661\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 356.5948 - val_loss: 495.0634\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 346.9861 - val_loss: 483.3038\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 338.7787 - val_loss: 473.3397\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 331.0844 - val_loss: 461.4584\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 322.7317 - val_loss: 450.7487\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 315.3018 - val_loss: 442.1931\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 307.8759 - val_loss: 431.9279\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 301.1305 - val_loss: 420.5892\n",
      "10/10 [==============================] - 0s 908us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 37269.2305 - val_loss: 17334.5312\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 9906.0908 - val_loss: 5044.9707\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4878.1738 - val_loss: 3828.5291\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4264.5430 - val_loss: 3346.5305\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3702.2129 - val_loss: 2911.6587\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3201.6912 - val_loss: 2499.3530\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2754.7747 - val_loss: 2131.3103\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2368.8333 - val_loss: 1811.5708\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2027.7281 - val_loss: 1539.0024\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1724.9353 - val_loss: 1306.5806\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1479.0726 - val_loss: 1115.9923\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1276.4706 - val_loss: 964.9135\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1103.0262 - val_loss: 842.9915\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 968.3884 - val_loss: 747.4894\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 856.9824 - val_loss: 669.0148\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 768.8583 - val_loss: 603.3635\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 694.7979 - val_loss: 550.4547\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 634.3674 - val_loss: 507.5282\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 582.8674 - val_loss: 470.0890\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 537.3214 - val_loss: 438.3889\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 500.6331 - val_loss: 411.4261\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 470.7306 - val_loss: 386.3677\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 440.3299 - val_loss: 366.2387\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 415.5316 - val_loss: 347.4905\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 393.8983 - val_loss: 329.2617\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 373.5603 - val_loss: 313.3260\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 355.9752 - val_loss: 298.8588\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 338.6077 - val_loss: 285.1872\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 323.8124 - val_loss: 273.0952\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 309.3989 - val_loss: 261.7676\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 296.5541 - val_loss: 252.0279\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 284.8015 - val_loss: 242.8013\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 274.3181 - val_loss: 234.3954\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 264.0792 - val_loss: 228.8331\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 256.1344 - val_loss: 220.1536\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 246.7056 - val_loss: 214.4602\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 240.7622 - val_loss: 214.4632\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 233.6224 - val_loss: 203.4978\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 226.1617 - val_loss: 198.6059\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 220.0428 - val_loss: 199.3363\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 217.3626 - val_loss: 189.5199\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 208.6684 - val_loss: 185.2506\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 204.5605 - val_loss: 186.3645\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 200.7301 - val_loss: 178.2043\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 194.6057 - val_loss: 177.0073\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.0924 - val_loss: 171.5605\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 186.6337 - val_loss: 169.3245\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 183.4110 - val_loss: 165.7661\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 181.1724 - val_loss: 163.0166\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 178.9585 - val_loss: 161.3945\n",
      "10/10 [==============================] - 0s 890us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 93249.0547 - val_loss: 49962.3711\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 31773.2598 - val_loss: 13211.3721\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 8945.4961 - val_loss: 5369.2227\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 5065.4458 - val_loss: 5008.4229\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 4606.7642 - val_loss: 4576.5576\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4228.8330 - val_loss: 4139.4438\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3844.7197 - val_loss: 3706.7661\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3467.7915 - val_loss: 3253.2092\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3049.0642 - val_loss: 2844.9128\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2661.8875 - val_loss: 2496.2979\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2332.8552 - val_loss: 2180.1499\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2035.2983 - val_loss: 1874.0498\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1761.0371 - val_loss: 1648.0480\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1537.0865 - val_loss: 1453.1171\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1350.7991 - val_loss: 1292.2705\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1190.6490 - val_loss: 1134.8646\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1060.7605 - val_loss: 1003.0093\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 954.4301 - val_loss: 911.9951\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 860.7303 - val_loss: 827.1060\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 792.1212 - val_loss: 771.4869\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 723.7032 - val_loss: 699.7239\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 673.9005 - val_loss: 661.2200\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 631.8914 - val_loss: 617.2682\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 593.3848 - val_loss: 576.5917\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 560.0893 - val_loss: 547.5806\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 529.6385 - val_loss: 519.6250\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 506.3835 - val_loss: 494.3049\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 482.1150 - val_loss: 471.5067\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 462.6296 - val_loss: 458.9359\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 442.1137 - val_loss: 433.9676\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 422.2236 - val_loss: 417.7646\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 406.3032 - val_loss: 401.9035\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 392.6656 - val_loss: 391.6534\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 377.8343 - val_loss: 370.9115\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 362.9867 - val_loss: 359.7172\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 352.1566 - val_loss: 348.2322\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 340.6768 - val_loss: 337.1906\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 328.9405 - val_loss: 323.1010\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 318.1533 - val_loss: 312.4025\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 310.5577 - val_loss: 301.9557\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 299.4698 - val_loss: 292.7990\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 290.7337 - val_loss: 285.1748\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 282.7381 - val_loss: 277.0070\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 275.3209 - val_loss: 269.0095\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 268.2926 - val_loss: 262.8652\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 259.6768 - val_loss: 253.0785\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 254.2610 - val_loss: 254.6545\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 247.8393 - val_loss: 239.3643\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 242.2710 - val_loss: 233.1753\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 236.8118 - val_loss: 228.3814\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 159164.6250 - val_loss: 88126.2188\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 52051.2344 - val_loss: 23987.6055\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 12930.3770 - val_loss: 5832.7129\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3618.1567 - val_loss: 2605.9641\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2209.6658 - val_loss: 2216.8459\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2031.7875 - val_loss: 2108.1399\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1937.7466 - val_loss: 2013.1129\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1837.3949 - val_loss: 1907.6730\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1735.0000 - val_loss: 1803.1832\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1627.8105 - val_loss: 1696.8424\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1513.3545 - val_loss: 1576.8252\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1348.5190 - val_loss: 1294.4060\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1019.5724 - val_loss: 950.8993\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 758.9272 - val_loss: 740.0488\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 605.9376 - val_loss: 609.7138\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 511.3611 - val_loss: 532.6979\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 448.3816 - val_loss: 470.3625\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 397.9705 - val_loss: 427.4054\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 363.4964 - val_loss: 389.1677\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 329.6640 - val_loss: 358.8047\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 303.3011 - val_loss: 334.2338\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 278.5001 - val_loss: 313.4437\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 259.4809 - val_loss: 294.8171\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 244.7453 - val_loss: 280.7369\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 231.0146 - val_loss: 268.1806\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 216.4444 - val_loss: 258.3489\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 207.6071 - val_loss: 249.4032\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.8646 - val_loss: 239.4594\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 189.9083 - val_loss: 232.3516\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 183.1863 - val_loss: 229.6534\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.1232 - val_loss: 220.8722\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 172.8811 - val_loss: 216.0986\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 167.2339 - val_loss: 212.3682\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.2506 - val_loss: 209.3761\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.1749 - val_loss: 206.6378\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 156.9014 - val_loss: 206.4248\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 153.7968 - val_loss: 200.0337\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 151.3739 - val_loss: 196.9242\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.1632 - val_loss: 194.1871\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 144.7048 - val_loss: 191.6892\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 142.0331 - val_loss: 190.2084\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 139.9074 - val_loss: 187.3547\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.6392 - val_loss: 186.3860\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.8949 - val_loss: 185.5169\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 135.3409 - val_loss: 181.7273\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 132.2592 - val_loss: 179.6716\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 131.4756 - val_loss: 177.6928\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 128.9971 - val_loss: 177.1058\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.4309 - val_loss: 176.9256\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 127.5213 - val_loss: 172.1557\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 6968.7148 - val_loss: 2563.2615\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2649.1050 - val_loss: 2116.1082\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2221.8604 - val_loss: 1953.1777\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2048.2490 - val_loss: 1813.5649\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1890.7711 - val_loss: 1686.8485\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1745.9532 - val_loss: 1559.4274\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1615.3701 - val_loss: 1451.4729\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1501.5430 - val_loss: 1356.7231\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1387.6008 - val_loss: 1249.7438\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1286.5266 - val_loss: 1156.4077\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1198.6228 - val_loss: 1089.6805\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1113.1010 - val_loss: 1001.8167\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1029.5527 - val_loss: 929.6857\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 953.2120 - val_loss: 880.2440\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 883.7108 - val_loss: 806.9509\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 822.8342 - val_loss: 765.8133\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 767.4622 - val_loss: 706.5264\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 711.4671 - val_loss: 658.1857\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 662.3962 - val_loss: 610.0591\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 618.6331 - val_loss: 582.2478\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 575.0734 - val_loss: 534.5447\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 535.1085 - val_loss: 525.0466\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 501.9605 - val_loss: 470.4211\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 473.4257 - val_loss: 441.0367\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 438.6756 - val_loss: 420.8505\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 412.6315 - val_loss: 390.9736\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 388.4835 - val_loss: 386.4610\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 367.6285 - val_loss: 354.4560\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 353.3872 - val_loss: 331.8545\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 324.1972 - val_loss: 320.0635\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 308.8810 - val_loss: 305.1939\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 293.2458 - val_loss: 285.8500\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 285.1812 - val_loss: 273.0938\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 264.4935 - val_loss: 260.6554\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 250.7432 - val_loss: 250.4220\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 250.2831 - val_loss: 241.5840\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 233.2165 - val_loss: 233.4452\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 221.0313 - val_loss: 221.3708\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 212.9595 - val_loss: 213.1580\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.3685 - val_loss: 208.6695\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 196.8472 - val_loss: 199.9149\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 191.4142 - val_loss: 200.6319\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.4011 - val_loss: 189.0090\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 177.1641 - val_loss: 186.7237\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 175.6789 - val_loss: 178.0355\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 168.9227 - val_loss: 177.9166\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 162.7234 - val_loss: 170.2167\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 160.1566 - val_loss: 167.3087\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.8201 - val_loss: 163.2915\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 150.0004 - val_loss: 162.1606\n",
      "10/10 [==============================] - 0s 900us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 191609.4375 - val_loss: 135350.2969\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 101948.0625 - val_loss: 67279.6406\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 48760.3789 - val_loss: 29749.1816\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 20728.1719 - val_loss: 11376.9268\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 7744.2817 - val_loss: 3803.6323\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2742.5781 - val_loss: 1325.1774\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1196.8558 - val_loss: 735.9708\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 829.0471 - val_loss: 639.2664\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 750.1231 - val_loss: 627.9304\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 728.2795 - val_loss: 619.8124\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 713.4478 - val_loss: 609.4636\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 698.8547 - val_loss: 598.5143\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 684.6878 - val_loss: 586.7861\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 669.5286 - val_loss: 576.2867\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 655.6101 - val_loss: 563.7667\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 641.4971 - val_loss: 551.6921\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 627.0762 - val_loss: 540.6387\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 614.5371 - val_loss: 530.9692\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 601.7780 - val_loss: 517.4150\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 586.4969 - val_loss: 509.0694\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 575.4840 - val_loss: 500.5897\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 561.8115 - val_loss: 488.8003\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 549.2407 - val_loss: 477.3223\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 537.6799 - val_loss: 470.1058\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 526.4658 - val_loss: 461.5289\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 517.1973 - val_loss: 451.3946\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 504.7752 - val_loss: 445.2455\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 495.8220 - val_loss: 439.0538\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 484.9715 - val_loss: 428.8134\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 476.1549 - val_loss: 422.0472\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 467.3457 - val_loss: 415.5262\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 459.0289 - val_loss: 408.8018\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 450.8072 - val_loss: 404.6043\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 443.0804 - val_loss: 397.4711\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 435.8134 - val_loss: 391.2775\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 428.8822 - val_loss: 386.6752\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 421.7707 - val_loss: 380.6089\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 415.9492 - val_loss: 375.7511\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 409.5670 - val_loss: 372.2774\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 403.7688 - val_loss: 367.4623\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 398.1611 - val_loss: 364.7563\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 393.1100 - val_loss: 358.2715\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 387.8634 - val_loss: 355.2775\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 383.0204 - val_loss: 352.1830\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 379.0153 - val_loss: 348.2350\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 374.3833 - val_loss: 346.5630\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 369.4714 - val_loss: 341.5263\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 365.8207 - val_loss: 338.9844\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 361.7771 - val_loss: 335.1161\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 357.7737 - val_loss: 333.4795\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 6ms/step - loss: 265963.2500 - val_loss: 197844.5000\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 152418.3125 - val_loss: 105534.9531\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 74632.1641 - val_loss: 42957.6445\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 24372.1133 - val_loss: 9634.5381\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 5453.7480 - val_loss: 3677.5603\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3208.3853 - val_loss: 3349.4829\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2941.0415 - val_loss: 3055.7903\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2684.0173 - val_loss: 2799.0713\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2450.9692 - val_loss: 2534.3123\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2214.9734 - val_loss: 2282.5850\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1994.6948 - val_loss: 2054.7466\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1789.7930 - val_loss: 1849.4803\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1584.0829 - val_loss: 1661.8541\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1397.6445 - val_loss: 1474.0936\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1237.4119 - val_loss: 1313.0194\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1105.0931 - val_loss: 1186.3849\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 994.2355 - val_loss: 1088.4379\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 902.5503 - val_loss: 1004.3445\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 832.8354 - val_loss: 939.6202\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 777.8550 - val_loss: 881.3351\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 734.6731 - val_loss: 830.7672\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 695.9268 - val_loss: 786.4944\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 662.4039 - val_loss: 746.8812\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 633.2523 - val_loss: 709.3463\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 605.0242 - val_loss: 679.0036\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 584.5102 - val_loss: 649.3504\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 560.3505 - val_loss: 619.2816\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 537.6098 - val_loss: 595.5637\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 525.4628 - val_loss: 568.0699\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 503.1944 - val_loss: 546.8582\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 485.4927 - val_loss: 526.4273\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 470.5742 - val_loss: 506.6623\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 457.5456 - val_loss: 491.2085\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 445.6439 - val_loss: 474.5568\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 431.3581 - val_loss: 456.7729\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 417.9777 - val_loss: 442.6982\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 406.4736 - val_loss: 427.5663\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 396.1181 - val_loss: 417.5550\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 389.3550 - val_loss: 412.4711\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 388.5077 - val_loss: 392.0888\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 368.9328 - val_loss: 382.2022\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 359.8694 - val_loss: 372.6360\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 353.1548 - val_loss: 361.7403\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 345.3437 - val_loss: 354.7720\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 334.3058 - val_loss: 341.2627\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 327.0581 - val_loss: 332.3829\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 317.1756 - val_loss: 324.9478\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 311.0304 - val_loss: 316.4914\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 305.6307 - val_loss: 311.0874\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 298.0632 - val_loss: 299.1863\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 123295.4688 - val_loss: 96975.2500\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 79277.7188 - val_loss: 61016.3359\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 49070.2539 - val_loss: 36899.3438\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 29145.8691 - val_loss: 21338.2070\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 16512.1504 - val_loss: 11719.8486\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 8884.5908 - val_loss: 6144.9995\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4610.3501 - val_loss: 3133.6306\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2377.7151 - val_loss: 1686.8823\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1351.1923 - val_loss: 1030.1963\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 916.6053 - val_loss: 767.7942\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 741.4581 - val_loss: 675.1929\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 678.4815 - val_loss: 637.5269\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 651.9311 - val_loss: 619.0281\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 636.9625 - val_loss: 606.4468\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 625.5919 - val_loss: 595.2712\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 614.0475 - val_loss: 585.0406\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 602.7725 - val_loss: 573.9290\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 591.6641 - val_loss: 563.5752\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 580.9378 - val_loss: 552.9663\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 569.7768 - val_loss: 541.8406\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 559.2587 - val_loss: 531.4665\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 547.3688 - val_loss: 520.9602\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 536.6479 - val_loss: 510.6012\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 525.5305 - val_loss: 500.0697\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 514.9367 - val_loss: 489.9112\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 504.4171 - val_loss: 479.9102\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 494.9503 - val_loss: 470.0511\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 484.1768 - val_loss: 460.4043\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 474.1944 - val_loss: 451.1954\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 464.8615 - val_loss: 441.5412\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 455.4185 - val_loss: 432.3057\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 445.7030 - val_loss: 423.7086\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 436.2397 - val_loss: 414.4588\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 427.2196 - val_loss: 406.2274\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 418.5669 - val_loss: 397.8119\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 409.8342 - val_loss: 389.7202\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 401.4891 - val_loss: 381.7036\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 393.3548 - val_loss: 373.7688\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 385.4762 - val_loss: 366.5580\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 377.8688 - val_loss: 358.9420\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 370.1033 - val_loss: 351.8759\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 362.5783 - val_loss: 344.5918\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 355.3728 - val_loss: 337.9721\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 348.3486 - val_loss: 331.3167\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 341.3369 - val_loss: 324.6866\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 334.7834 - val_loss: 318.2169\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 328.3965 - val_loss: 312.1913\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 322.7753 - val_loss: 306.7003\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 315.9671 - val_loss: 300.9732\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 310.6313 - val_loss: 295.5577\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 211411.4375 - val_loss: 145678.8281\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 99005.9219 - val_loss: 58115.0430\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 35910.7734 - val_loss: 18462.5039\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 12962.7627 - val_loss: 8513.6221\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 8551.6533 - val_loss: 7299.7207\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 7791.2197 - val_loss: 6596.2275\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 6962.3564 - val_loss: 5954.9307\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 6220.1812 - val_loss: 5323.1665\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 5534.3945 - val_loss: 4746.0508\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4906.0806 - val_loss: 4203.6069\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4309.0425 - val_loss: 3702.2249\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 3768.1899 - val_loss: 3264.8931\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3289.3232 - val_loss: 2861.3411\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2855.7485 - val_loss: 2477.4324\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2452.2102 - val_loss: 2138.0422\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2111.6331 - val_loss: 1857.9519\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1808.3402 - val_loss: 1598.1013\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1532.5264 - val_loss: 1375.4817\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1301.1814 - val_loss: 1177.1215\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1103.0548 - val_loss: 1013.1050\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 942.2806 - val_loss: 877.8403\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 804.2681 - val_loss: 768.0674\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 694.5839 - val_loss: 668.0682\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 599.6984 - val_loss: 593.5265\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 519.3824 - val_loss: 534.3393\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 459.6702 - val_loss: 479.8384\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 410.5071 - val_loss: 435.7993\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 371.9614 - val_loss: 407.2916\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 343.1017 - val_loss: 372.8525\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 309.9955 - val_loss: 351.6901\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 290.2600 - val_loss: 331.3147\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 270.3497 - val_loss: 315.9380\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 259.4674 - val_loss: 303.7887\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 244.8776 - val_loss: 288.2953\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 233.3086 - val_loss: 277.3189\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 224.9710 - val_loss: 268.1322\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 216.5947 - val_loss: 260.0895\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 210.3674 - val_loss: 253.1935\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 203.4734 - val_loss: 245.8484\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 198.0238 - val_loss: 239.6364\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 193.5504 - val_loss: 234.2246\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 189.2469 - val_loss: 228.8620\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 185.3552 - val_loss: 225.5406\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 182.2352 - val_loss: 218.9240\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.7356 - val_loss: 214.5757\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 176.0251 - val_loss: 210.0855\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 171.5000 - val_loss: 208.5558\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.5667 - val_loss: 202.3924\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 166.7259 - val_loss: 202.1430\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 163.4535 - val_loss: 196.5592\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 2238.3430 - val_loss: 1786.8956\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1534.9459 - val_loss: 1244.5654\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1006.7144 - val_loss: 828.6039\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 667.1692 - val_loss: 586.7947\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 478.4304 - val_loss: 436.0872\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 353.5656 - val_loss: 322.6415\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 257.3938 - val_loss: 246.2521\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 197.0465 - val_loss: 197.1454\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 159.9032 - val_loss: 168.4668\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.9593 - val_loss: 147.4224\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.1047 - val_loss: 135.4950\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 117.8908 - val_loss: 129.6875\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 112.5620 - val_loss: 125.1383\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 108.6686 - val_loss: 119.1448\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 106.3170 - val_loss: 116.4590\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 104.4477 - val_loss: 113.3736\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 102.3823 - val_loss: 111.8175\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 101.4873 - val_loss: 108.7716\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 100.0147 - val_loss: 111.1151\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 100.5649 - val_loss: 109.3307\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 98.1727 - val_loss: 105.3589\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 98.5210 - val_loss: 105.8329\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 98.0482 - val_loss: 102.3177\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 96.9353 - val_loss: 104.5198\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 95.3131 - val_loss: 104.3152\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 95.9381 - val_loss: 100.3840\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 94.9652 - val_loss: 100.1135\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 93.6413 - val_loss: 99.3174\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 93.5671 - val_loss: 97.6559\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 92.8076 - val_loss: 98.8823\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 93.4863 - val_loss: 96.8216\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 92.6272 - val_loss: 97.6832\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 91.2595 - val_loss: 97.9711\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 90.8466 - val_loss: 95.3326\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 89.3990 - val_loss: 98.3779\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 90.0125 - val_loss: 95.4553\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 91.4678 - val_loss: 93.4031\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 88.1208 - val_loss: 92.8431\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 87.0634 - val_loss: 92.0117\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 88.3652 - val_loss: 92.7751\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 87.2745 - val_loss: 92.0462\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 86.5030 - val_loss: 90.5708\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 85.8378 - val_loss: 97.7235\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 88.4123 - val_loss: 112.1481\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 92.2497 - val_loss: 89.1087\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 85.1666 - val_loss: 90.5238\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 84.6546 - val_loss: 95.0401\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 85.3141 - val_loss: 95.3814\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 84.6932 - val_loss: 89.5151\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 86.5514 - val_loss: 86.8823\n",
      "10/10 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 268142.7812 - val_loss: 222055.0469\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 180186.7031 - val_loss: 137463.7344\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 97850.1875 - val_loss: 62104.1484\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 39836.9766 - val_loss: 22256.9102\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 13526.2314 - val_loss: 7633.9604\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4980.3477 - val_loss: 3903.8652\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3196.9573 - val_loss: 3208.1292\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2891.2271 - val_loss: 3092.0479\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2797.9373 - val_loss: 3016.7048\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2728.2485 - val_loss: 2937.6279\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2653.5212 - val_loss: 2863.5081\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2583.7437 - val_loss: 2789.3625\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2516.1941 - val_loss: 2718.8037\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2447.6062 - val_loss: 2652.8887\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2383.6836 - val_loss: 2582.1042\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 2318.6421 - val_loss: 2516.7542\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2255.1001 - val_loss: 2458.3000\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2197.2920 - val_loss: 2394.7002\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2142.6208 - val_loss: 2334.3948\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2082.4673 - val_loss: 2278.3608\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2029.5911 - val_loss: 2223.5405\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1977.4152 - val_loss: 2167.7346\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1926.8842 - val_loss: 2116.6196\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1877.0118 - val_loss: 2064.2822\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1830.7878 - val_loss: 2018.2848\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1784.4797 - val_loss: 1968.5764\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1740.0865 - val_loss: 1922.5215\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1696.1534 - val_loss: 1876.7971\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1655.1921 - val_loss: 1835.3097\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1614.0293 - val_loss: 1790.9634\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1575.7537 - val_loss: 1752.8427\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 1537.6918 - val_loss: 1712.9183\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1502.9274 - val_loss: 1674.8285\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1465.0125 - val_loss: 1636.4082\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1431.9341 - val_loss: 1602.5782\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1398.4355 - val_loss: 1565.0386\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1367.0092 - val_loss: 1530.3505\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1333.7520 - val_loss: 1499.4429\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1307.5631 - val_loss: 1464.5701\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1273.7534 - val_loss: 1435.7017\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1245.6422 - val_loss: 1403.1506\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1220.6305 - val_loss: 1374.5287\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1193.7120 - val_loss: 1343.2544\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1163.9326 - val_loss: 1317.4902\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1139.0773 - val_loss: 1288.1802\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1115.7102 - val_loss: 1260.6469\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1088.3500 - val_loss: 1236.7870\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1066.3646 - val_loss: 1210.3704\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1042.9225 - val_loss: 1183.9097\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1021.4011 - val_loss: 1160.1913\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 58934.7031 - val_loss: 23553.8047\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 16315.6201 - val_loss: 10547.5635\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 10388.6768 - val_loss: 9626.1523\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 9405.2666 - val_loss: 8656.0508\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 8510.5098 - val_loss: 7785.9424\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 7698.6631 - val_loss: 7085.5225\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 6974.7593 - val_loss: 6381.1504\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 6338.4307 - val_loss: 5766.4448\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 5734.0850 - val_loss: 5242.1621\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 5214.1729 - val_loss: 4735.2866\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 4747.6289 - val_loss: 4316.9678\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 4322.5474 - val_loss: 3911.1621\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3957.2869 - val_loss: 3566.6865\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3641.6965 - val_loss: 3270.3696\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3306.4932 - val_loss: 2975.1072\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3043.5964 - val_loss: 2720.5642\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2793.1282 - val_loss: 2498.2825\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2567.4558 - val_loss: 2290.6162\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2370.4929 - val_loss: 2107.7422\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2192.4668 - val_loss: 1945.2827\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2030.2074 - val_loss: 1803.1423\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1886.5338 - val_loss: 1664.7968\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1754.6389 - val_loss: 1545.2866\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1640.6855 - val_loss: 1436.2676\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1527.9988 - val_loss: 1336.4795\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1428.9475 - val_loss: 1247.7727\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1336.8970 - val_loss: 1165.1842\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1254.6633 - val_loss: 1088.6389\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1176.9927 - val_loss: 1020.3132\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1110.4520 - val_loss: 957.3274\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1042.7247 - val_loss: 898.7375\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 983.5491 - val_loss: 843.8775\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 922.6753 - val_loss: 797.3398\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 871.8818 - val_loss: 750.1772\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 825.9261 - val_loss: 708.7667\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 782.9024 - val_loss: 678.0181\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 742.7844 - val_loss: 636.4937\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 704.2032 - val_loss: 605.3605\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 669.7395 - val_loss: 578.0778\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 639.6843 - val_loss: 555.5200\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 609.5308 - val_loss: 525.7917\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 582.9452 - val_loss: 506.3219\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 553.6938 - val_loss: 481.1501\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 532.7312 - val_loss: 463.1898\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 512.9136 - val_loss: 446.7509\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 489.8905 - val_loss: 429.0179\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 472.0696 - val_loss: 414.6961\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 454.9071 - val_loss: 406.6367\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 440.3749 - val_loss: 396.8502\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 424.1662 - val_loss: 378.1862\n",
      "10/10 [==============================] - 0s 1ms/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 67136.5000 - val_loss: 31882.6602\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 16374.8877 - val_loss: 5745.1855\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 3322.9639 - val_loss: 2221.9343\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2093.6729 - val_loss: 1970.5370\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1948.0029 - val_loss: 1877.0135\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1862.9756 - val_loss: 1807.4727\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1791.9054 - val_loss: 1739.1755\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1722.6990 - val_loss: 1671.1646\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1656.8895 - val_loss: 1600.6770\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1585.9434 - val_loss: 1535.1138\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1517.9634 - val_loss: 1464.7196\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1451.9806 - val_loss: 1399.5627\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1390.3933 - val_loss: 1337.5317\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1326.9802 - val_loss: 1277.8618\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1267.3657 - val_loss: 1216.3379\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1210.7375 - val_loss: 1160.6556\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1154.8444 - val_loss: 1106.1224\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1101.8579 - val_loss: 1056.7799\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1052.0304 - val_loss: 1007.2045\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1006.0444 - val_loss: 961.3333\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 961.5001 - val_loss: 915.2966\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 920.9441 - val_loss: 876.2870\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 880.1434 - val_loss: 836.2645\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 845.0854 - val_loss: 801.3696\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 809.7729 - val_loss: 766.5742\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 776.9552 - val_loss: 734.9189\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 746.4280 - val_loss: 704.2833\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 716.3652 - val_loss: 674.8743\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 690.7385 - val_loss: 649.5336\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 664.0050 - val_loss: 621.4651\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 638.9137 - val_loss: 600.4051\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 615.4123 - val_loss: 575.2310\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 592.5596 - val_loss: 552.3420\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 571.0626 - val_loss: 530.5102\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 550.3340 - val_loss: 514.7133\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 531.6832 - val_loss: 491.7910\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 510.4342 - val_loss: 474.7393\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 491.9886 - val_loss: 455.3320\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 473.8077 - val_loss: 438.0276\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 456.8850 - val_loss: 421.6359\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 441.3275 - val_loss: 407.3273\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 425.6494 - val_loss: 391.3614\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 410.8174 - val_loss: 377.3168\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 398.0485 - val_loss: 367.8344\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 383.8477 - val_loss: 350.3255\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 370.2750 - val_loss: 338.2944\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 356.5995 - val_loss: 326.9977\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 347.4334 - val_loss: 316.6248\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 332.4991 - val_loss: 302.8098\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 321.0737 - val_loss: 293.6313\n",
      "10/10 [==============================] - 0s 889us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 2139.1450 - val_loss: 2052.4617\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1734.2332 - val_loss: 1795.7743\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1606.0928 - val_loss: 1694.2294\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1556.2959 - val_loss: 1654.9200\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1536.7070 - val_loss: 1643.6824\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1529.0399 - val_loss: 1637.9779\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1523.8757 - val_loss: 1633.9652\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1520.7170 - val_loss: 1630.6747\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1518.0681 - val_loss: 1627.5181\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1515.4641 - val_loss: 1625.3142\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1513.4663 - val_loss: 1623.3162\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1511.5796 - val_loss: 1621.4254\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1509.8647 - val_loss: 1619.5852\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1508.1758 - val_loss: 1617.7526\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1506.4662 - val_loss: 1615.9564\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1504.7666 - val_loss: 1614.1548\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1503.0812 - val_loss: 1612.3224\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1501.4315 - val_loss: 1610.5061\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1499.7672 - val_loss: 1608.7312\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1498.1403 - val_loss: 1606.9779\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1496.5219 - val_loss: 1605.2181\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1494.9117 - val_loss: 1603.5637\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1493.3303 - val_loss: 1601.9161\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1491.7448 - val_loss: 1600.2598\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1490.1556 - val_loss: 1598.6146\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1488.5721 - val_loss: 1596.9567\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1486.9897 - val_loss: 1595.3152\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1485.4167 - val_loss: 1593.6886\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1483.8448 - val_loss: 1592.0641\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1482.2686 - val_loss: 1590.4531\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1480.7043 - val_loss: 1588.8204\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1479.1299 - val_loss: 1587.1987\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1477.5579 - val_loss: 1585.5883\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1475.9987 - val_loss: 1583.9701\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1474.4304 - val_loss: 1582.3501\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1472.8564 - val_loss: 1580.7394\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1471.2949 - val_loss: 1579.1129\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1469.7262 - val_loss: 1577.4957\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1468.1625 - val_loss: 1575.8782\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1466.6068 - val_loss: 1574.2549\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1465.0350 - val_loss: 1572.6533\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1463.4769 - val_loss: 1571.0509\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1461.9242 - val_loss: 1569.4333\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1460.3646 - val_loss: 1567.8312\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1458.7996 - val_loss: 1566.2355\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1457.2484 - val_loss: 1564.6207\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1455.6992 - val_loss: 1562.9988\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1454.1368 - val_loss: 1561.3981\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1452.5801 - val_loss: 1559.7920\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1451.0288 - val_loss: 1558.1873\n",
      "10/10 [==============================] - 0s 891us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 4031.0049 - val_loss: 1779.7308\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1718.5073 - val_loss: 1579.3694\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1446.3889 - val_loss: 1395.1799\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1236.8972 - val_loss: 1197.6633\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1065.4187 - val_loss: 1020.6099\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 920.1568 - val_loss: 888.9356\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 802.7061 - val_loss: 778.8619\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 711.0569 - val_loss: 683.2311\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 631.5609 - val_loss: 620.5344\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 569.1829 - val_loss: 562.0614\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 514.8341 - val_loss: 505.1376\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 470.0165 - val_loss: 472.6276\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 430.4998 - val_loss: 425.9230\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 393.6559 - val_loss: 380.3300\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 360.6525 - val_loss: 362.7407\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 333.6682 - val_loss: 326.9511\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 307.1632 - val_loss: 304.6516\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 285.9331 - val_loss: 280.8801\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 267.6152 - val_loss: 259.2533\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 250.4618 - val_loss: 240.9804\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 235.8793 - val_loss: 234.1716\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 221.4248 - val_loss: 214.0934\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 211.1158 - val_loss: 202.6741\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 201.0852 - val_loss: 195.6714\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 190.7304 - val_loss: 187.0489\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.6479 - val_loss: 178.8592\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 177.4225 - val_loss: 169.8215\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.7948 - val_loss: 166.2946\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 164.7516 - val_loss: 162.9871\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 161.2212 - val_loss: 154.1995\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 156.8058 - val_loss: 149.9028\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 154.5299 - val_loss: 146.4948\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 148.4707 - val_loss: 146.1532\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 147.4661 - val_loss: 142.8401\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 146.4367 - val_loss: 145.1617\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 143.5270 - val_loss: 146.2997\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 138.8766 - val_loss: 133.1872\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 135.3425 - val_loss: 135.7565\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 136.2160 - val_loss: 127.2028\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 132.7066 - val_loss: 124.7460\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 128.9799 - val_loss: 122.7863\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.0920 - val_loss: 120.3727\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 126.5181 - val_loss: 118.0154\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 124.4747 - val_loss: 118.1249\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 120.9144 - val_loss: 114.2701\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 119.2666 - val_loss: 113.5100\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 116.9482 - val_loss: 111.1250\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 116.2582 - val_loss: 110.6607\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 113.2179 - val_loss: 109.2045\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 112.1406 - val_loss: 106.5191\n",
      "10/10 [==============================] - 0s 891us/step\n",
      "Epoch 1/50\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 13135.6426 - val_loss: 4126.2969\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 2320.0640 - val_loss: 2012.5004\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1828.8960 - val_loss: 1831.3014\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1632.8774 - val_loss: 1690.1499\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1498.0062 - val_loss: 1525.3687\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1360.8114 - val_loss: 1351.7627\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1221.1025 - val_loss: 1194.7737\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 1082.0857 - val_loss: 1032.3379\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 954.6877 - val_loss: 891.3571\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 824.6979 - val_loss: 753.3377\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 723.1733 - val_loss: 655.5482\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 633.4777 - val_loss: 566.3270\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 560.3960 - val_loss: 488.9575\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 503.1758 - val_loss: 438.4062\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 455.2899 - val_loss: 395.8375\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 418.6240 - val_loss: 363.1026\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 387.0513 - val_loss: 340.4007\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 364.4894 - val_loss: 324.1316\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 344.0028 - val_loss: 305.8108\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 325.7392 - val_loss: 292.8678\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 311.7217 - val_loss: 279.9600\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 302.0909 - val_loss: 278.8386\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 288.8485 - val_loss: 263.7303\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 283.8981 - val_loss: 256.0443\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 271.5484 - val_loss: 249.6574\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 264.0064 - val_loss: 246.4826\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 258.1673 - val_loss: 237.6595\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 251.4892 - val_loss: 232.7140\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 244.0037 - val_loss: 227.6630\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 237.7197 - val_loss: 227.9663\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 232.3303 - val_loss: 222.7690\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 226.8958 - val_loss: 213.4538\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 222.6574 - val_loss: 211.7640\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 216.4283 - val_loss: 205.2406\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 213.1866 - val_loss: 204.2947\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 208.6262 - val_loss: 206.4055\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 204.3880 - val_loss: 195.0745\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 199.8580 - val_loss: 189.9774\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 195.2181 - val_loss: 190.3421\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 192.1187 - val_loss: 194.8717\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 191.5366 - val_loss: 183.8872\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.5466 - val_loss: 185.5565\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 184.6391 - val_loss: 199.8935\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 179.1658 - val_loss: 170.3010\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 174.1340 - val_loss: 173.7423\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 173.3826 - val_loss: 164.7374\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 169.5344 - val_loss: 161.0339\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 170.4796 - val_loss: 160.9668\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 165.8476 - val_loss: 155.4554\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 162.8055 - val_loss: 152.9514\n",
      "10/10 [==============================] - 0s 848us/step\n"
     ]
    }
   ],
   "source": [
    "list_of_errors=[]\n",
    "for i in range(50):\n",
    "    list_of_errors.append(MyModel1_eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[116.13311687817048, 917.8674138718476, 176.60300560353008, 279.4791250098204, 116.17053442544567, 130.27758561655162, 685.2225994867708, 78.75534213939568, 275.65701636110185, 187.6269338022907, 195.0015621823212, 134.48102239738802, 149.98438775137421, 430.086924937092, 166.55925955148933, 868.5631158273688, 119.50003316028884, 149.23413236254123, 167.0330136177824, 453.7931677758882, 129.1268086758615, 143.70105118144755, 108.70196770115466, 205.32330590195954, 247.1626566879188, 712.0566665742055, 428.2100529198277, 265.26192401473014, 101.80125986047152, 1171.0444295960672, 234.65939004171173, 96.86195257720921, 247.23003019158185, 212.54288053848566, 420.5891721680927, 161.39442323793338, 228.3813753959024, 172.155739244802, 162.1606065246963, 333.4794548924201, 299.18625960119505, 295.55765660620284, 196.55916356099712, 86.88229399013541, 1160.1913099993758, 378.1861673476912, 293.63130889070493, 1558.187316659654, 106.51913621349537, 152.9513671105634]\n"
     ]
    }
   ],
   "source": [
    "print(list_of_errors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CALCULATING MEAN AND STANDARD DEVIATION OF MEAN_SQUARED_ERRORS OBTAINED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_of_errors=np.mean(list_of_errors)\n",
    "std_of_errors=np.std(list_of_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of mean squared errors is 322.1545284132991\n",
      "Standard Deviation of mean squared errors is 311.7192830548688\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean of mean squared errors is\",mean_of_errors)\n",
    "print(\"Standard Deviation of mean squared errors is\",std_of_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f5816e6188795d1cc8afa4306b69c5e3a103f064a75e820fe776234e4cf83e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
